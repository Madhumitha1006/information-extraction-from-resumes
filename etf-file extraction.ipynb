{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fa4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df176ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfbox\n",
    "p = pdfbox.PDFBox()\n",
    "p.extract_text('Akash-Verma.pdf')\n",
    "with open('Akash-Verma.txt', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "592a11ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Akash Verma\\nNew Delhi, Delhi\\n-Email me on Indeed: http://www.indeed.com/r/Akash-Verma/848734e32bf98980\\nSoftware Engineer with around 3 years of experience in building software and team collaboration,\\nseeking full-timeÂ\\xa0\\nSoftware Engineer roles.\\nWork Experience\\nSoftware Engineer\\nIncedo Inc\\nJuly 2020 to Present\\nI created 3 projects in my current company using python. I'm currently working on 4th project. These\\nprojects are namely hardware diagnostic tool, thermal tool, certification tool, manufacturing tool.\\nSoftware Engineer\\nEndovision - Delhi, Delhi\\nPresent\\nEducation\\nBachelor's in Computer Science & Engineering\\nAjay Kumar Garg Engineering College, Ghaziabad - Ghaziabad, Uttar Pradesh\\nAugust 2016 to October 2020\\nSkills / IT Skills\\nâ€¢ MYSQL\\nâ€¢ Python\\nâ€¢ Data structures\\nâ€¢ MongoDB\\nâ€¢ Docker\\nâ€¢ Git\\nâ€¢ Linux\\nâ€¢ Ansible\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195aeb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11c7e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9b5c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akash PROPN compound B PERSON Verma\n",
      "Verma PROPN compound I PERSON Delhi\n",
      "\n",
      " SPACE dep I PERSON Verma\n",
      "New PROPN compound I PERSON Delhi\n",
      "Delhi PROPN nsubj I PERSON -Email\n",
      ", PUNCT punct O  Delhi\n",
      "Delhi PROPN nsubj B GPE -Email\n",
      "\n",
      " SPACE dep O  Delhi\n",
      "-Email VERB ROOT O  -Email\n",
      "me PRON dobj O  -Email\n",
      "on ADP prep O  -Email\n",
      "Indeed ADV pcomp O  on\n",
      ": PUNCT punct O  -Email\n",
      "http://www.indeed.com/r/Akash-Verma/848734e32bf98980 X amod O  Engineer\n",
      "\n",
      " SPACE dep O  http://www.indeed.com/r/Akash-Verma/848734e32bf98980\n",
      "Software PROPN compound B ORG Engineer\n",
      "Engineer PROPN dobj I ORG -Email\n",
      "with ADP prep O  Engineer\n",
      "around ADP quantmod B DATE 3\n",
      "3 NUM nummod I DATE years\n",
      "years NOUN pobj I DATE with\n",
      "of ADP prep O  years\n",
      "experience NOUN pobj O  of\n",
      "in ADP prep O  experience\n",
      "building VERB pcomp O  in\n",
      "software NOUN nmod O  collaboration\n",
      "and CCONJ cc O  software\n",
      "team NOUN conj O  software\n",
      "collaboration NOUN dobj O  building\n",
      ", PUNCT punct O  Engineer\n",
      "\n",
      " SPACE dep O  ,\n",
      "seeking VERB advcl O  -Email\n",
      "full ADJ amod O  timeÂ\n",
      "- PUNCT punct O  timeÂ\n",
      "timeÂ NOUN nmod O  Engineer\n",
      " \n",
      " SPACE dep O  timeÂ\n",
      "Software PROPN compound B ORG Engineer\n",
      "Engineer PROPN compound I ORG roles\n",
      "roles NOUN dobj O  seeking\n",
      ". PUNCT punct O  -Email\n",
      "\n",
      " SPACE dep O  .\n",
      "Work PROPN compound O  Inc\n",
      "Experience PROPN compound O  Engineer\n",
      "\n",
      " SPACE dep O  Experience\n",
      "Software PROPN compound B ORG Engineer\n",
      "Engineer PROPN nmod I ORG Inc\n",
      "\n",
      " SPACE dep O  Engineer\n",
      "Incedo PROPN appos B ORG Engineer\n",
      "Inc PROPN compound I ORG July\n",
      "\n",
      " SPACE dep O  Inc\n",
      "July PROPN npadvmod B DATE created\n",
      "2020 NUM nummod I DATE July\n",
      "to ADP prep O  July\n",
      "Present PROPN pobj O  to\n",
      "\n",
      " SPACE dep O  Present\n",
      "I PRON nsubj O  created\n",
      "created VERB ROOT O  created\n",
      "3 NUM nummod B CARDINAL projects\n",
      "projects NOUN dobj O  created\n",
      "in ADP prep O  created\n",
      "my PRON poss O  company\n",
      "current ADJ amod O  company\n",
      "company NOUN pobj O  in\n",
      "using VERB advcl O  created\n",
      "python NOUN dobj O  using\n",
      ". PUNCT punct O  created\n",
      "I PRON nsubj O  working\n",
      "'m AUX aux O  working\n",
      "currently ADV advmod O  working\n",
      "working VERB ROOT O  working\n",
      "on ADP prep O  working\n",
      "4th ADJ amod B ORDINAL project\n",
      "project NOUN pobj O  on\n",
      ". PUNCT punct O  working\n",
      "These DET det O  projects\n",
      "\n",
      " SPACE dep O  These\n",
      "projects NOUN nsubj O  are\n",
      "are AUX ROOT O  are\n",
      "namely ADV advmod O  are\n",
      "hardware ADJ nmod O  tool\n",
      "diagnostic ADJ amod O  tool\n",
      "tool NOUN attr O  are\n",
      ", PUNCT punct O  tool\n",
      "thermal ADJ amod O  tool\n",
      "tool NOUN conj O  tool\n",
      ", PUNCT punct O  tool\n",
      "certification NOUN compound O  tool\n",
      "tool NOUN conj O  tool\n",
      ", PUNCT punct O  tool\n",
      "manufacturing VERB compound O  tool\n",
      "tool NOUN appos O  tool\n",
      ". PUNCT punct O  are\n",
      "\n",
      " SPACE dep O  .\n",
      "Software PROPN compound B ORG Delhi\n",
      "Engineer PROPN compound I ORG Delhi\n",
      "\n",
      " SPACE dep I ORG Engineer\n",
      "Endovision PROPN compound I ORG Delhi\n",
      "- PUNCT punct I ORG Delhi\n",
      "Delhi PROPN ROOT I ORG Delhi\n",
      ", PUNCT punct O  Delhi\n",
      "Delhi PROPN compound B GPE Bachelor\n",
      "\n",
      " SPACE dep O  Delhi\n",
      "Present PROPN compound O  Bachelor\n",
      "\n",
      " SPACE dep O  Present\n",
      "Education PROPN compound O  Bachelor\n",
      "\n",
      " SPACE dep O  Education\n",
      "Bachelor PROPN appos B ORG Delhi\n",
      "'s PART case O  Bachelor\n",
      "in ADP prep O  Bachelor\n",
      "Computer PROPN nmod B ORG Science\n",
      "Science PROPN nmod I ORG College\n",
      "& CCONJ cc I ORG Science\n",
      "Engineering PROPN compound I ORG Ajay\n",
      "\n",
      " SPACE dep O  Engineering\n",
      "Ajay PROPN conj B PERSON Science\n",
      "Kumar PROPN compound I PERSON College\n",
      "Garg PROPN compound B ORG College\n",
      "Engineering PROPN compound I ORG College\n",
      "College PROPN pobj I ORG in\n",
      ", PUNCT punct O  College\n",
      "Ghaziabad PROPN compound B GPE Ghaziabad\n",
      "- PUNCT punct O  Ghaziabad\n",
      "Ghaziabad PROPN conj B GPE College\n",
      ", PUNCT punct O  Ghaziabad\n",
      "Uttar PROPN compound B ORG Pradesh\n",
      "Pradesh PROPN compound I ORG August\n",
      "\n",
      " SPACE dep O  Pradesh\n",
      "August PROPN conj B DATE Ghaziabad\n",
      "2016 NUM nummod I DATE August\n",
      "to ADP prep I DATE Bachelor\n",
      "October PROPN pobj I DATE to\n",
      "2020 NUM nummod I DATE October\n",
      "\n",
      " SPACE dep O  2020\n",
      "Skills PROPN nmod B ORG Skills\n",
      "/ SYM punct I ORG IT\n",
      "IT PROPN compound I ORG Skills\n",
      "Skills NOUN nmod I ORG Git\n",
      "\n",
      " SPACE dep O  Skills\n",
      "â€¢ PUNCT punct B PRODUCT Skills\n",
      "MYSQL PROPN nmod I PRODUCT Python\n",
      "\n",
      " SPACE dep I PRODUCT MYSQL\n",
      "â€¢ PUNCT punct B PRODUCT MYSQL\n",
      "Python PROPN nmod I PRODUCT structures\n",
      "\n",
      " SPACE dep O  Python\n",
      "â€¢ PUNCT punct B PRODUCT Python\n",
      "Data PROPN compound I PRODUCT structures\n",
      "structures NOUN nmod O  MongoDB\n",
      "\n",
      " SPACE dep O  structures\n",
      "â€¢ NUM punct B PRODUCT structures\n",
      "MongoDB NUM appos I PRODUCT Skills\n",
      "\n",
      " SPACE dep I PRODUCT MongoDB\n",
      "â€¢ PUNCT punct B PRODUCT MongoDB\n",
      "Docker PROPN nmod I PRODUCT Git\n",
      "\n",
      " SPACE dep O  Docker\n",
      "â€¢ PUNCT punct B PRODUCT Docker\n",
      "Git PROPN nmod I PRODUCT Linux\n",
      "\n",
      " SPACE dep O  Git\n",
      "â€¢ PUNCT punct B PRODUCT Git\n",
      "Linux PROPN appos I PRODUCT Delhi\n",
      "\n",
      " SPACE dep O  Linux\n",
      "â€¢ PUNCT punct B PRODUCT Linux\n",
      "Ansible PROPN amod I PRODUCT Linux\n",
      "\n",
      " SPACE dep O  Ansible\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print (token.text, token.pos_, token.dep_,token.ent_iob_,token.ent_type_,token.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8c52f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Akash Verma\n",
       "New Delhi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Delhi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</br>-Email me on Indeed: http://www.indeed.com/r/Akash-Verma/848734e32bf98980</br>\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Software Engineer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " with \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    around 3 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of experience in building software and team collaboration,</br>seeking full-timeÂ </br>\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Software Engineer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " roles.</br>Work Experience</br>\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Software Engineer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Incedo Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    July 2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " to Present</br>I created \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " projects in my current company using python. I'm currently working on \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    4th\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " project. These</br>projects are namely hardware diagnostic tool, thermal tool, certification tool, manufacturing tool.</br>\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Software Engineer\n",
       "Endovision - Delhi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Delhi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</br>Present</br>Education</br>\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bachelor\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "'s in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Computer Science &amp; Engineering\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ajay Kumar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Garg Engineering College\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ghaziabad\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " - \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ghaziabad\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Uttar Pradesh\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    August 2016 to October 2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Skills / IT Skills\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    â€¢ MYSQL\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    â€¢ Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    â€¢ Data\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " structures</br>\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    â€¢ MongoDB\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    â€¢ Docker\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    â€¢ Git\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    â€¢ Linux\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    â€¢ Ansible\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82157875",
   "metadata": {},
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Create the root element\n",
    "root = ET.Element(\"ROOT\")\n",
    "sentence_element = ET.SubElement(root, \"SENT\")\n",
    "# Set to keep track of tokens in subtree\n",
    "subtree_tokens = set()\n",
    "    \n",
    "for token in doc:\n",
    "    if token in subtree_tokens:\n",
    "        continue\n",
    "    \n",
    "    parent = token\n",
    "    \n",
    "    while parent and parent!=parent.head and parent.pos_ not in [\"NOUN\", \"PROPN\", \"VERB\"]:\n",
    "        parent = parent.head\n",
    "    subtree_tokens.add(parent)\n",
    "        \n",
    "    if parent.pos_ == \"VERB\":\n",
    "        verb_subtree_element = ET.SubElement(sentence_element, f\"DVP_{parent.text}\")\n",
    "        \n",
    "        for child in parent.subtree:\n",
    "            subtree_tokens.add(child)\n",
    "            \n",
    "            if child.dep_ in [\"nsubj\", \"dobj\", \"nsubjpass\"]:\n",
    "                # Encapsulate the entire dependency subtree rooted at the child\n",
    "                subtree_element_depverb = ET.SubElement(verb_subtree_element, f\"{child.dep_}_{parent.text}\")\n",
    "        \n",
    "                # Create a token element\n",
    "                token_element_ner = ET.SubElement(subtree_element_depverb, child.ent_type_)\n",
    "                # Create a token element\n",
    "                token_element_pos = ET.SubElement(token_element_ner, child.pos_)\n",
    "                token_element_pos.text = str(child.text)\n",
    "            else:\n",
    "                # Create a token element\n",
    "                token_element_ner = ET.SubElement(verb_subtree_element, child.ent_type_)\n",
    "                # Create a token element\n",
    "                token_element_pos = ET.SubElement(token_element_ner, child.pos_)\n",
    "                token_element_pos.text = str(child.text)\n",
    "                    \n",
    "    elif parent.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "        noun_subtree_element = ET.SubElement(sentence_element, f\"DNP_{parent.text}\")\n",
    "        \n",
    "        for child in parent.subtree:\n",
    "            subtree_tokens.add(child)\n",
    "            \n",
    "            if child.dep_ in [\"nsubj\", \"dobj\", \"nsubjpass\"]:\n",
    "                # Encapsulate the entire dependency subtree rooted at the child\n",
    "                subtree_element_depverb = ET.SubElement(noun_subtree_element, f\"{child.dep_}_{parent.text}\")\n",
    "        \n",
    "                # Create a token element\n",
    "                token_element_ner = ET.SubElement(subtree_element_depverb, child.ent_type_)\n",
    "                # Create a token element\n",
    "                token_element_pos = ET.SubElement(token_element_ner, child.pos_)\n",
    "                token_element_pos.text = str(child.text)\n",
    "            else:\n",
    "                # Create a token element\n",
    "                token_element_ner = ET.SubElement(noun_subtree_element, child.ent_type_)\n",
    "                # Create a token element\n",
    "                token_element_pos = ET.SubElement(token_element_ner, child.pos_)\n",
    "                token_element_pos.text = str(child.text)\n",
    "    else:\n",
    "        subtree_tokens.add(token)\n",
    "        # Create a token element\n",
    "        token_element_ner = ET.SubElement(sentence_element, token.ent_type_)\n",
    "        \n",
    "        # Create a token element\n",
    "        token_element_pos = ET.SubElement(token_element_ner, token.pos_)\n",
    "        token_element_pos.text = str(token.text)\n",
    "\n",
    "# Convert the XML tree to a string\n",
    "xml_string = ET.tostring(root, encoding=\"unicode\")\n",
    "\n",
    "# Print or save the XML string\n",
    "print(xml_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad168cda",
   "metadata": {},
   "source": [
    "# gazette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02eabef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies= pd.read_csv('companies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e544dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities=pd.read_csv('cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c2ccde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=pd.read_csv('names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a78bd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokyo',\n",
       " 'Jakarta',\n",
       " 'Delhi',\n",
       " 'Guangzhou',\n",
       " 'Mumbai',\n",
       " 'Manila',\n",
       " 'Shanghai',\n",
       " 'São Paulo',\n",
       " 'Seoul',\n",
       " 'Mexico City',\n",
       " 'Cairo',\n",
       " 'New York',\n",
       " 'Dhaka',\n",
       " 'Beijing',\n",
       " 'Kolkāta',\n",
       " 'Bangkok',\n",
       " 'Shenzhen',\n",
       " 'Moscow',\n",
       " 'Buenos Aires',\n",
       " 'Lagos',\n",
       " 'Istanbul',\n",
       " 'Karachi',\n",
       " 'Bangalore',\n",
       " 'Ho Chi Minh City',\n",
       " 'Ōsaka',\n",
       " 'Chengdu',\n",
       " 'Tehran',\n",
       " 'Kinshasa',\n",
       " 'Rio de Janeiro',\n",
       " 'Chennai',\n",
       " 'Xi’an',\n",
       " 'Lahore',\n",
       " 'Chongqing',\n",
       " 'Los Angeles',\n",
       " 'Baoding',\n",
       " 'London',\n",
       " 'Paris',\n",
       " 'Linyi',\n",
       " 'Dongguan',\n",
       " 'Hyderābād',\n",
       " 'Tianjin',\n",
       " 'Lima',\n",
       " 'Wuhan',\n",
       " 'Nanyang',\n",
       " 'Hangzhou',\n",
       " 'Foshan',\n",
       " 'Nagoya',\n",
       " 'Taipei',\n",
       " 'Tongshan',\n",
       " 'Luanda',\n",
       " 'Zhoukou',\n",
       " 'Ganzhou',\n",
       " 'Kuala Lumpur',\n",
       " 'Heze',\n",
       " 'Quanzhou',\n",
       " 'Chicago',\n",
       " 'Nanjing',\n",
       " 'Jining',\n",
       " 'Hanoi',\n",
       " 'Pune',\n",
       " 'Fuyang',\n",
       " 'Ahmedabad',\n",
       " 'Johannesburg',\n",
       " 'Bogotá',\n",
       " 'Dar es Salaam',\n",
       " 'Shenyang',\n",
       " 'Khartoum',\n",
       " 'Shangqiu',\n",
       " 'Cangzhou',\n",
       " 'Hong Kong',\n",
       " 'Shaoyang',\n",
       " 'Zhanjiang',\n",
       " 'Yancheng',\n",
       " 'Hengyang',\n",
       " 'Riyadh',\n",
       " 'Zhumadian',\n",
       " 'Santiago',\n",
       " 'Xingtai',\n",
       " 'Chattogram',\n",
       " 'Bijie',\n",
       " 'Shangrao',\n",
       " 'Zunyi',\n",
       " 'Sūrat',\n",
       " 'Surabaya',\n",
       " 'Huanggang',\n",
       " 'Maoming',\n",
       " 'Nanchong',\n",
       " 'Xinyang',\n",
       " 'Madrid',\n",
       " 'Baghdad',\n",
       " 'Qujing',\n",
       " 'Jieyang',\n",
       " 'Singapore',\n",
       " 'Prayagraj',\n",
       " 'Liaocheng',\n",
       " 'Dalian',\n",
       " 'Yulin',\n",
       " 'Changde',\n",
       " 'Qingdao',\n",
       " 'Douala',\n",
       " 'Miami',\n",
       " 'Nangandao',\n",
       " 'Pudong',\n",
       " 'Xiangyang',\n",
       " 'Dallas',\n",
       " 'Houston',\n",
       " 'Zhengzhou',\n",
       " 'Lu’an',\n",
       " 'Dezhou',\n",
       " 'Jinan',\n",
       " 'Giza',\n",
       " 'Zhaotong',\n",
       " 'Yichun',\n",
       " 'Nairobi',\n",
       " 'Guadalajara',\n",
       " 'Philadelphia',\n",
       " 'Ankara',\n",
       " 'Tai’an',\n",
       " 'Dazhou',\n",
       " 'Langfang',\n",
       " 'Yongzhou',\n",
       " 'Toronto',\n",
       " 'Suihua',\n",
       " 'Saint Petersburg',\n",
       " 'Qiqihar',\n",
       " 'Suzhou',\n",
       " 'Monterrey',\n",
       " 'Belo Horizonte',\n",
       " 'Weinan',\n",
       " 'Rangoon',\n",
       " 'Zhangzhou',\n",
       " 'Yuncheng',\n",
       " 'Xianyang',\n",
       " 'Guilin',\n",
       " 'Atlanta',\n",
       " 'Taizhou',\n",
       " 'Kāshān',\n",
       " 'Bozhou',\n",
       " 'Abidjan',\n",
       " 'Suqian',\n",
       " 'Huaihua',\n",
       " 'Ji’an',\n",
       " 'Xiaoganzhan',\n",
       " 'Pingdingshan',\n",
       " 'Jiujiang',\n",
       " 'Alexandria',\n",
       " 'Mianyang',\n",
       " 'Sydney',\n",
       " 'Huanglongsi',\n",
       " 'Washington',\n",
       " 'Barcelona',\n",
       " 'Changsha',\n",
       " 'Chenzhou',\n",
       " 'Anqing',\n",
       " 'Jiangmen',\n",
       " 'Xinpu',\n",
       " 'Yibin',\n",
       " 'Yangzhou',\n",
       " 'Melbourne',\n",
       " 'Berlin',\n",
       " 'Hengshui',\n",
       " 'Timbío',\n",
       " 'Kunming',\n",
       " 'Yiyang',\n",
       " 'Guigang',\n",
       " 'Changchun',\n",
       " 'Jiangguanchi',\n",
       " 'Casablanca',\n",
       " 'Meizhou',\n",
       " 'Zhangjiakou',\n",
       " 'Chifeng',\n",
       " 'Ürümqi',\n",
       " 'Suzhou',\n",
       " 'İzmir',\n",
       " 'Linfen',\n",
       " 'Shantou',\n",
       " 'Kabul',\n",
       " 'Mogadishu',\n",
       " 'Luzhou',\n",
       " 'Hefei',\n",
       " 'Boston',\n",
       " 'Liuzhou',\n",
       " 'Zhaoqing',\n",
       " 'Xiaoxita',\n",
       " 'Shijiazhuang',\n",
       " 'Ningbo',\n",
       " 'Fuzhou',\n",
       " 'Phoenix',\n",
       " 'Zhuzhou',\n",
       " 'Amman',\n",
       " 'Chuzhou',\n",
       " 'Jeddah',\n",
       " 'Qingyuan',\n",
       " 'Loudi',\n",
       " 'Binzhou',\n",
       " 'Deyang',\n",
       " 'Taiyuan',\n",
       " 'Kano',\n",
       " 'Wuhu',\n",
       " 'Nanning',\n",
       " 'Harbin',\n",
       " 'Abuja',\n",
       " 'Yokohama',\n",
       " 'Baojishi',\n",
       " 'Zaozhuang',\n",
       " 'Xiamen',\n",
       " 'Neijiang',\n",
       " 'Fuzhou',\n",
       " 'Baicheng',\n",
       " 'Anshan',\n",
       " 'Medan',\n",
       " 'Yulinshi',\n",
       " 'Wenzhou',\n",
       " 'Changzhou',\n",
       " 'Puyang',\n",
       " 'Jiaozuo',\n",
       " 'Nanchang',\n",
       " 'Ibadan',\n",
       " 'Hechi',\n",
       " 'Detroit',\n",
       " 'Montréal',\n",
       " 'Busan',\n",
       " 'Hohhot',\n",
       " 'Seattle',\n",
       " 'Algiers',\n",
       " 'Hanzhong',\n",
       " 'Tangshan',\n",
       " 'Shiyan',\n",
       " 'Lucknow',\n",
       " 'Siping',\n",
       " 'Mashhad',\n",
       " 'Boankra',\n",
       " 'Changzhi',\n",
       " 'Dubai',\n",
       " 'Qinzhou',\n",
       " 'Guiyang',\n",
       " 'Bengbu',\n",
       " 'San Francisco',\n",
       " 'Bazhou',\n",
       " 'Qincheng',\n",
       " 'Suining',\n",
       " 'Wuxi',\n",
       " 'Leshan',\n",
       " 'Putian',\n",
       " 'Zhenjiang',\n",
       " 'Faisalabad',\n",
       " 'Guang’an',\n",
       " 'Tongren',\n",
       " 'Santa Cruz',\n",
       " 'Qinhuangdao',\n",
       " 'Tongliao',\n",
       " 'Jinzhou',\n",
       " 'Heyuan',\n",
       " 'San Diego',\n",
       " 'Jaipur',\n",
       " 'Xinzhou',\n",
       " 'Lanzhou',\n",
       " 'Wuzhou',\n",
       " 'Athens',\n",
       " 'Addis Ababa',\n",
       " 'Chaoyang',\n",
       " 'Brasília',\n",
       " 'Taichung',\n",
       " 'Kuwait City',\n",
       " 'Budapest',\n",
       " 'Shaoguan',\n",
       " 'Shanwei',\n",
       " 'Quezon City',\n",
       " 'Rizhao',\n",
       " 'Kyiv',\n",
       " 'Sanaa',\n",
       " 'Meishan',\n",
       " 'Incheon',\n",
       " 'Guatemala City',\n",
       " 'Birmingham',\n",
       " 'Zhongshan',\n",
       " 'Ningde',\n",
       " 'Weihai',\n",
       " 'Daqing',\n",
       " 'Bursa',\n",
       " 'Salvador',\n",
       " 'Rome',\n",
       " 'Haikou',\n",
       " 'La Paz',\n",
       " 'Xiangtan',\n",
       " 'Pyongyang',\n",
       " 'Minneapolis',\n",
       " 'Omdurman',\n",
       " 'Malang',\n",
       " 'Mudanjiang',\n",
       " 'Stuttgart',\n",
       " 'Brooklyn',\n",
       " 'Kaohsiung',\n",
       " 'Guayaquil',\n",
       " 'Lisbon',\n",
       " 'Longyan',\n",
       " 'Tieling',\n",
       " 'Manchester',\n",
       " 'Baotou',\n",
       " 'Handan',\n",
       " 'Cawnpore',\n",
       " 'Dingxi',\n",
       " 'Nanping',\n",
       " 'Tampa',\n",
       " 'Zigong',\n",
       " 'Maracaibo',\n",
       " 'Chaozhou',\n",
       " 'Mbuji-Mayi',\n",
       " 'Denver',\n",
       " 'Gulou',\n",
       " 'Weifang',\n",
       " 'Huai’an',\n",
       " 'Zibo',\n",
       " 'Ankang',\n",
       " 'Baoshan',\n",
       " 'Antananarivo',\n",
       " 'Huludao',\n",
       " 'Munich',\n",
       " 'Yanjiang',\n",
       " 'Santo Domingo',\n",
       " 'Sanming',\n",
       " 'Tashkent',\n",
       " 'Longba',\n",
       " 'Yangjiang',\n",
       " 'Jiamusi',\n",
       " 'Luohe',\n",
       " 'Lincang',\n",
       " 'Medellín',\n",
       " 'Xuanzhou',\n",
       " 'Yunfu',\n",
       " 'Shaoxing',\n",
       " 'Yantai',\n",
       " 'Huizhou',\n",
       " 'Lishui',\n",
       " 'Mirzāpur',\n",
       " 'Hamburg',\n",
       " 'Guangyuan',\n",
       " 'Cali',\n",
       " 'Lusaka',\n",
       " 'Huangshi',\n",
       " 'Xining',\n",
       " 'Ouagadougou',\n",
       " 'Daegu',\n",
       " 'Fortaleza',\n",
       " 'Yaoundé',\n",
       " 'Jilin',\n",
       " 'Dandong',\n",
       " 'Zhuhai',\n",
       " 'Lianshan',\n",
       " 'Yingkou',\n",
       " 'Antalya',\n",
       " 'Nāgpur',\n",
       " 'Queens',\n",
       " 'Accra',\n",
       " 'Bekasi',\n",
       " 'Ghāziābād',\n",
       " 'Yuxi',\n",
       " 'Luoyang',\n",
       " 'Brisbane',\n",
       " 'Anshun',\n",
       " 'Depok',\n",
       " 'Shangzhou',\n",
       " 'Huainan',\n",
       " 'Colombo',\n",
       " 'Kuaidamao',\n",
       " 'Baku',\n",
       " 'Fukuoka',\n",
       " 'Yan’an',\n",
       " 'Jincheng',\n",
       " 'Vancouver',\n",
       " 'Nantong',\n",
       " 'Tangerang',\n",
       " 'Caracas',\n",
       " 'Sanmenxia',\n",
       " 'Laibin',\n",
       " 'Konya',\n",
       " 'Manaus',\n",
       " 'Eşfahān',\n",
       " 'Qinbaling',\n",
       " 'Baltimore',\n",
       " 'Ma’anshan',\n",
       " 'Shengli',\n",
       " 'Gaoping',\n",
       " 'Taizhou',\n",
       " 'Harare',\n",
       " 'Kowloon',\n",
       " 'Las Vegas',\n",
       " 'Havana',\n",
       " 'Perth',\n",
       " 'Phnom Penh',\n",
       " 'Puning',\n",
       " 'Huaibei',\n",
       " 'Qingyang',\n",
       " 'Haiphong',\n",
       " 'Chongzuo',\n",
       " 'Rawalpindi',\n",
       " 'Yushan',\n",
       " 'St. Louis',\n",
       " 'Kumasi',\n",
       " 'Vadodara',\n",
       " 'Hezhou',\n",
       " 'Pingliang',\n",
       " 'Portland',\n",
       " 'Vishākhapatnam',\n",
       " 'Gujranwala',\n",
       " 'Baicheng',\n",
       " 'Gaziantep',\n",
       " 'Fushun',\n",
       " 'Riverside',\n",
       " 'Bamako',\n",
       " 'Quito',\n",
       " 'Minsk',\n",
       " 'Tijuana',\n",
       " 'Bamenda',\n",
       " 'Boosaaso',\n",
       " 'Indore',\n",
       " 'Şanlıurfa',\n",
       " 'Vienna',\n",
       " 'Karaj',\n",
       " 'Kananga',\n",
       " 'Peshawar',\n",
       " 'Sapporo',\n",
       " 'Ecatepec',\n",
       " 'Pingxiang',\n",
       " 'Orlando',\n",
       " 'Aleppo',\n",
       " 'Sacramento',\n",
       " 'Almaty',\n",
       " 'San Juan',\n",
       " 'San Antonio',\n",
       " 'Yinchuan',\n",
       " 'Thāne',\n",
       " 'Santos',\n",
       " 'Blantyre',\n",
       " 'Bucharest',\n",
       " 'Curitiba',\n",
       " 'Multan',\n",
       " 'Tainan',\n",
       " 'Xiping',\n",
       " 'Port Harcourt',\n",
       " 'Warsaw',\n",
       " 'Jixi',\n",
       " 'Saidu Sharif',\n",
       " 'Liaoyang',\n",
       " 'Beihai',\n",
       " 'Meru',\n",
       " 'Brazzaville',\n",
       " 'Fuxin',\n",
       " 'Wuwei',\n",
       " 'Mersin',\n",
       " 'Bhopāl',\n",
       " 'Lubumbashi',\n",
       " 'Denpasar',\n",
       " 'Davao',\n",
       " 'Shuyangzha',\n",
       " 'Adana',\n",
       " 'Damascus',\n",
       " 'Brussels',\n",
       " 'Hyderabad City',\n",
       " 'Diyarbakır',\n",
       " 'San Jose',\n",
       " 'Chinchvad',\n",
       " 'Montevideo',\n",
       " 'Pittsburgh',\n",
       " 'Shuozhou',\n",
       " 'Cincinnati',\n",
       " 'Benxi',\n",
       " 'Baiyin',\n",
       " 'Mosul',\n",
       " 'Manhattan',\n",
       " 'Caloocan City',\n",
       " 'Kampala',\n",
       " 'Patna',\n",
       " 'Tegucigalpa',\n",
       " 'Cleveland',\n",
       " 'Sanzhou',\n",
       " 'Changshu',\n",
       " 'Mecca',\n",
       " 'Heihe',\n",
       " 'Jingdezhen',\n",
       " 'Conakry',\n",
       " 'Recife',\n",
       " 'Indianapolis',\n",
       " 'Austin',\n",
       " 'Sangereng',\n",
       " 'Kansas City',\n",
       " 'Zhongli',\n",
       " 'Novosibirsk',\n",
       " 'Bilāspur',\n",
       " 'Semarang',\n",
       " 'Ludhiāna',\n",
       " 'Nārāyanganj',\n",
       " 'Stockholm',\n",
       " 'Chengtangcun',\n",
       " 'Āgra',\n",
       " 'Balandougou',\n",
       " 'Agwār',\n",
       " 'León de los Aldama',\n",
       " 'Yopougon',\n",
       " 'Puebla',\n",
       " 'Madurai',\n",
       " 'Hebi',\n",
       " 'Córdoba',\n",
       " 'Shīrāz',\n",
       " 'Jamshedpur',\n",
       " 'Tabrīz',\n",
       " 'Huzhou',\n",
       " 'Columbus',\n",
       " 'Sofia',\n",
       " 'Kawasaki',\n",
       " 'San José',\n",
       " 'Aba',\n",
       " 'Palembang',\n",
       " 'Zhangjiajie',\n",
       " 'Kōbe',\n",
       " 'Jiaxing',\n",
       " 'Charlotte',\n",
       " 'Guiping',\n",
       " 'Lianjiang',\n",
       " 'Ximeicun',\n",
       " 'Jianguang',\n",
       " 'Yucheng',\n",
       " 'Panama City',\n",
       " 'Xushan',\n",
       " 'Belém',\n",
       " 'Virginia Beach',\n",
       " 'Leizhou',\n",
       " 'Gwangju',\n",
       " 'Nāsik',\n",
       " 'Porto Alegre',\n",
       " 'Valencia',\n",
       " 'Onitsha',\n",
       " 'Abu Dhabi',\n",
       " 'Daejeon',\n",
       " 'Zapopan',\n",
       " 'Bronx',\n",
       " 'Yekaterinburg',\n",
       " 'Huazhou',\n",
       " 'Kyōto',\n",
       " 'Jinhua',\n",
       " 'Amsterdam',\n",
       " 'Shuangyashan',\n",
       " 'Pizhou',\n",
       " 'El Kelaa des Srarhna',\n",
       " 'Dakar',\n",
       " 'Kharkiv',\n",
       " 'Yangshe',\n",
       " 'Guyuan',\n",
       " 'Rui’an',\n",
       " 'Khulna',\n",
       " 'Muscat',\n",
       " 'Wenling',\n",
       " 'Gaozhou',\n",
       " 'Farīdābād',\n",
       " 'Chizhou',\n",
       " 'Tel Aviv-Yafo',\n",
       " 'Ulaanbaatar',\n",
       " 'Goiânia',\n",
       " 'Fuqing',\n",
       " 'Kayseri',\n",
       " 'Wuzhong',\n",
       " 'Belgrade',\n",
       " 'Pingdu',\n",
       " 'Milan',\n",
       " 'Aurangābād',\n",
       " 'Copenhagen',\n",
       " 'Yangquan',\n",
       " 'Yutan',\n",
       " 'Huangshan',\n",
       " 'Auckland',\n",
       " 'Makassar',\n",
       " 'Santiago',\n",
       " 'Milwaukee',\n",
       " 'Rājkot',\n",
       " 'Prague',\n",
       " 'Samsun',\n",
       " 'Liangshi',\n",
       " 'Barranquilla',\n",
       " 'Saitama',\n",
       " 'Guarulhos',\n",
       " 'Al Başrah',\n",
       " 'Mandalay',\n",
       " 'Juárez',\n",
       " 'Xintai',\n",
       " 'Wusong',\n",
       " 'Meerut',\n",
       " 'Yushu',\n",
       " 'Rongcheng',\n",
       " 'Huazhou',\n",
       " 'Adelaide',\n",
       " 'Baishan',\n",
       " 'Dayan',\n",
       " 'Haicheng',\n",
       " 'Tripoli',\n",
       " 'Jiangyin',\n",
       " 'Yicheng',\n",
       " 'Huaiyin',\n",
       " 'Porto',\n",
       " 'Cacuaco',\n",
       " 'Soweto',\n",
       " 'Rosario',\n",
       " 'Canagatan',\n",
       " 'Helsinki',\n",
       " 'Jabalpur',\n",
       " 'Providence',\n",
       " 'Rucheng',\n",
       " 'Nizhniy Novgorod',\n",
       " 'Ahvāz',\n",
       " 'Jepara',\n",
       " 'Shaoyang',\n",
       " 'Comayagüela',\n",
       " 'Laiwu',\n",
       " 'Sharjah',\n",
       " 'Kalamboli',\n",
       " 'Jingling',\n",
       " 'Kazan',\n",
       " 'Suwon',\n",
       " 'Yongcheng',\n",
       " 'Sumedang',\n",
       " 'Calgary',\n",
       " 'Cần Thơ',\n",
       " 'Yiwu',\n",
       " 'Bagam',\n",
       " 'Beidao',\n",
       " 'Vasai',\n",
       " 'Xiangshui',\n",
       " 'Jacksonville',\n",
       " 'Akçaabat',\n",
       " 'Campinas',\n",
       " 'Dadukou',\n",
       " 'Mombasa',\n",
       " 'Lingcheng',\n",
       " 'Najafgarh',\n",
       " 'Vila Velha',\n",
       " 'Gāzipura',\n",
       " 'Chelyabinsk',\n",
       " 'Vārānasi',\n",
       " 'Xinyu',\n",
       " 'Qom',\n",
       " 'Hargeysa',\n",
       " 'Zhangye',\n",
       " 'Hiroshima',\n",
       " 'Maiduguri',\n",
       " 'Chiang Mai',\n",
       " 'Doha',\n",
       " 'Maputo',\n",
       " 'Mbandaka',\n",
       " 'Pikine',\n",
       " 'Medina',\n",
       " 'Srīnagar',\n",
       " 'Omsk',\n",
       " 'Dublin',\n",
       " 'Liaoyuan',\n",
       " 'Cilacap',\n",
       " 'Yingtan',\n",
       " 'Bandar Lampung',\n",
       " 'Samara',\n",
       " 'Guankou',\n",
       " 'Ulsan',\n",
       " 'Dhanbād',\n",
       " 'Dingzhou',\n",
       " 'Lianyuan',\n",
       " 'Rongcheng',\n",
       " 'Kaiyuan',\n",
       " 'Nay Pyi Taw',\n",
       " 'Zhuji',\n",
       " 'Kigali',\n",
       " 'Bukavu',\n",
       " 'Leiyang',\n",
       " 'Bafoussam',\n",
       " 'Yichun',\n",
       " 'Benin City',\n",
       " 'Rostov',\n",
       " 'Xiantao',\n",
       " 'Amritsar',\n",
       " 'Callao',\n",
       " 'Salt Lake City',\n",
       " 'Alīgarh',\n",
       " 'Shagamu',\n",
       " 'Yingchuan',\n",
       " 'Ciudad Nezahualcóyotl',\n",
       " 'Tbilisi',\n",
       " 'Guwāhāti',\n",
       " 'Ufa',\n",
       " 'Fès',\n",
       " 'São Luís',\n",
       " 'Biên Hòa',\n",
       " 'Sevilla',\n",
       " 'N’Djamena',\n",
       " 'Mexicali',\n",
       " 'Nezahualcóyotl',\n",
       " 'Ikare',\n",
       " 'Nashville',\n",
       " 'Tamale',\n",
       " 'Xibeijie',\n",
       " 'Yuyao',\n",
       " 'Hāora',\n",
       " 'Hanchuan',\n",
       " 'Gongzhuling',\n",
       " 'Krasnoyarsk',\n",
       " 'Cologne',\n",
       " 'Bujumbura',\n",
       " 'Bishkek',\n",
       " 'Zhufeng',\n",
       " 'São Gonçalo',\n",
       " 'Yerevan',\n",
       " 'Ezhou',\n",
       " 'Nur-Sultan',\n",
       " 'Tongjin',\n",
       " 'Nouakchott',\n",
       " 'Xiashi',\n",
       " 'Rānchi',\n",
       " 'Taixing',\n",
       " 'Vereeniging',\n",
       " 'Gwalior',\n",
       " 'Zhongwei',\n",
       " 'Goyang',\n",
       " 'Oslo',\n",
       " 'Vijayavāda',\n",
       " 'Chandīgarh',\n",
       " 'Edmonton',\n",
       " 'Sendai',\n",
       " 'Raleigh',\n",
       " 'Mizhou',\n",
       " 'Tunis',\n",
       " 'Xishan',\n",
       " 'Barquisimeto',\n",
       " 'Hegang',\n",
       " 'Voronezh',\n",
       " 'Perm',\n",
       " 'Changwon',\n",
       " 'Fangchenggang',\n",
       " 'Shouguang',\n",
       " 'Bogor',\n",
       " 'Cartagena',\n",
       " 'Matola',\n",
       " 'Jodhpur',\n",
       " 'Memphis',\n",
       " 'Ogbomoso',\n",
       " 'Rangapukur',\n",
       " 'Managua',\n",
       " 'Sanya',\n",
       " 'Shymkent',\n",
       " 'Wutong',\n",
       " 'Niamey',\n",
       " 'Shubrā al Khaymah',\n",
       " 'Linhai',\n",
       " 'Denizli',\n",
       " 'Maceió',\n",
       " 'Monrovia',\n",
       " 'Wafangdian',\n",
       " 'Zhongxiang',\n",
       " 'Louisville',\n",
       " 'Odesa',\n",
       " 'Thủ Đức',\n",
       " 'Volgograd',\n",
       " 'Islamabad',\n",
       " 'Port-au-Prince',\n",
       " 'Xinyi',\n",
       " 'Raipur',\n",
       " 'Arequipa',\n",
       " 'Richmond',\n",
       " 'Zaoyang',\n",
       " 'Buffalo',\n",
       " 'Shuizhai',\n",
       " 'Xingyi',\n",
       " 'Kota',\n",
       " 'Quetta',\n",
       " 'Kathmandu',\n",
       " 'Ottawa',\n",
       " 'Lilongwe',\n",
       " 'Asmara',\n",
       " 'Freetown',\n",
       " 'Vientiane',\n",
       " 'Jerusalem',\n",
       " 'Riga',\n",
       " 'Bangui',\n",
       " 'Dushanbe',\n",
       " 'Lomé',\n",
       " 'Ashgabat',\n",
       " 'Zagreb',\n",
       " 'Libreville',\n",
       " 'Cotonou',\n",
       " 'Pretoria',\n",
       " 'Vilnius',\n",
       " 'Winnipeg',\n",
       " 'Quebec City',\n",
       " 'Chisinau',\n",
       " 'Port Moresby',\n",
       " 'Skopje',\n",
       " 'Djibouti',\n",
       " 'Gaza',\n",
       " 'Kingston',\n",
       " 'Rabat',\n",
       " 'San Salvador',\n",
       " 'The Hague',\n",
       " 'Asunción',\n",
       " 'Juba',\n",
       " 'Maseru',\n",
       " 'Bissau',\n",
       " 'Valletta',\n",
       " 'Bratislava',\n",
       " 'Kitchener',\n",
       " 'Manama',\n",
       " 'Tallinn',\n",
       " 'Beirut',\n",
       " 'Cape Town',\n",
       " 'Tirana',\n",
       " 'Sarajevo',\n",
       " 'Wellington',\n",
       " 'Banjul',\n",
       " 'Halifax',\n",
       " 'Canberra',\n",
       " 'Yamoussoukro',\n",
       " 'Victoria',\n",
       " 'Nicosia',\n",
       " 'Windhoek',\n",
       " 'Saint-Denis',\n",
       " 'Porto-Novo',\n",
       " 'Sucre',\n",
       " 'Ljubljana',\n",
       " 'Nassau',\n",
       " 'Bloemfontein',\n",
       " 'Fort-de-France',\n",
       " 'New Delhi',\n",
       " 'Gaborone',\n",
       " 'Paramaribo',\n",
       " 'Dili',\n",
       " 'Dodoma',\n",
       " 'Georgetown',\n",
       " 'Gibraltar',\n",
       " 'Malabo',\n",
       " 'Suva',\n",
       " 'Nouméa',\n",
       " 'Pristina',\n",
       " 'Male',\n",
       " 'Port Louis',\n",
       " 'Podgorica',\n",
       " 'Willemstad',\n",
       " 'Bern',\n",
       " 'Gitega',\n",
       " 'Reykjavík',\n",
       " 'Luxembourg',\n",
       " 'Papeete',\n",
       " 'Praia',\n",
       " 'Sri Jayewardenepura Kotte',\n",
       " 'Bridgetown',\n",
       " 'Moroni',\n",
       " 'Thimphu',\n",
       " 'Mbabane',\n",
       " 'Honiara',\n",
       " 'Port of Spain',\n",
       " 'Castries',\n",
       " 'Putrajaya',\n",
       " 'Cayenne',\n",
       " 'São Tomé',\n",
       " 'Port-Vila',\n",
       " 'Bandar Seri Begawan',\n",
       " 'Monaco',\n",
       " 'Apia',\n",
       " 'Tarawa',\n",
       " 'Oranjestad',\n",
       " 'Saint Helier',\n",
       " 'Mamoudzou',\n",
       " 'Majuro',\n",
       " 'Douglas',\n",
       " 'George Town',\n",
       " 'Victoria',\n",
       " 'Kingstown',\n",
       " 'Andorra la Vella',\n",
       " 'Saint John’s',\n",
       " 'Nuku‘alofa',\n",
       " 'Nuuk',\n",
       " 'Belmopan',\n",
       " 'Roseau',\n",
       " 'Basseterre',\n",
       " 'Tórshavn',\n",
       " 'Road Town',\n",
       " 'Pago Pago',\n",
       " 'Grand Turk',\n",
       " 'Marigot',\n",
       " 'Palikir',\n",
       " 'Funafuti',\n",
       " 'Vaduz',\n",
       " 'Lobamba',\n",
       " 'Avarua',\n",
       " 'Saint George’s',\n",
       " 'San Marino',\n",
       " 'Tifariti',\n",
       " 'Philipsburg',\n",
       " 'Capitol Hill',\n",
       " 'Stanley',\n",
       " 'Hamilton',\n",
       " 'Vatican City',\n",
       " 'Alofi',\n",
       " 'Basse-Terre',\n",
       " 'Hagåtña',\n",
       " 'Jamestown',\n",
       " 'Brades',\n",
       " 'Yaren',\n",
       " 'Gustavia',\n",
       " 'Ngerulmud',\n",
       " 'Saint-Pierre',\n",
       " 'The Valley',\n",
       " 'Mata-Utu',\n",
       " 'Kingston',\n",
       " 'Longyearbyen',\n",
       " 'Adamstown',\n",
       " 'Flying Fish Cove',\n",
       " 'King Edward Point',\n",
       " 'Bareilly',\n",
       " 'Quảng Hà',\n",
       " 'Domaa-Ahenkro',\n",
       " 'Oklahoma City',\n",
       " 'Xingcheng',\n",
       " 'Dongtai',\n",
       " 'Yingcheng',\n",
       " 'Chiba',\n",
       " 'Al Mijlad',\n",
       " 'Pekanbaru',\n",
       " 'Luocheng',\n",
       " 'Dnipro',\n",
       " 'Danyang',\n",
       " 'Godē',\n",
       " 'Natal',\n",
       " 'Nada',\n",
       " 'Zamboanga City',\n",
       " 'Kirkuk',\n",
       " 'Bridgeport',\n",
       " 'Naples',\n",
       " 'Wuchuan',\n",
       " 'Huilong',\n",
       " 'Morelia',\n",
       " 'Málaga',\n",
       " 'Cebu City',\n",
       " 'Al Manşūrah',\n",
       " 'Coimbatore',\n",
       " 'Santo Domingo Este',\n",
       " 'Setagaya',\n",
       " 'Sŏngnam',\n",
       " 'Taishan',\n",
       " 'Teresina',\n",
       " 'Solāpur',\n",
       " 'Tangier',\n",
       " 'Kermānshāh',\n",
       " 'Krasnodar',\n",
       " 'Baidoa',\n",
       " 'Gaalkacyo',\n",
       " 'Anqiu',\n",
       " 'Feicheng',\n",
       " 'Seberang Jaya',\n",
       " 'El Alto',\n",
       " 'Kitakyūshū',\n",
       " 'Meishan',\n",
       " 'Khartoum North',\n",
       " 'Kisangani',\n",
       " 'Aguascalientes',\n",
       " 'Marrakech',\n",
       " 'Donetsk',\n",
       " 'Trujillo',\n",
       " 'New Orleans',\n",
       " 'Taihe',\n",
       " 'Trichinopoly',\n",
       " 'Xin’an',\n",
       " 'Taihecun',\n",
       " 'Kashgar',\n",
       " 'Naucalpan de Juárez',\n",
       " 'Çankaya',\n",
       " 'Santiago de Cuba',\n",
       " 'Owerri',\n",
       " 'Padang',\n",
       " 'Qingzhou',\n",
       " 'Lichuan',\n",
       " 'Santiago del Estero',\n",
       " 'Daye',\n",
       " 'Hengzhou',\n",
       " 'Fort Worth',\n",
       " 'Hartford',\n",
       " 'Esenyurt',\n",
       " 'Campo Grande',\n",
       " 'Zhuanghe',\n",
       " 'Bobo-Dioulasso',\n",
       " 'Ad Dammām',\n",
       " 'Quzhou',\n",
       " 'Lhasa',\n",
       " 'Jiaozhou',\n",
       " 'Bunia',\n",
       " 'Taguig City',\n",
       " 'Cancún',\n",
       " 'Mérida',\n",
       " 'Yangchun',\n",
       " 'Dengtalu',\n",
       " 'Morādābād',\n",
       " 'Antipolo',\n",
       " 'Abeokuta',\n",
       " 'Bucheon',\n",
       " 'Zhoushan',\n",
       " 'Tiruppūr',\n",
       " 'Natal',\n",
       " 'Chihuahua',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities['city'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b45ed1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gazette = {\n",
    "    \"city\": cities['city'].tolist(),\n",
    "    \"company\": companies['name'].tolist(),\n",
    "    \"names\": names['name'].tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfe77f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match in 'names' list.\n"
     ]
    }
   ],
   "source": [
    "child_text = \"chandran\"\n",
    "\n",
    "found_key = None\n",
    "\n",
    "# Iterate through the dictionary values\n",
    "for key, value_list in gazette.items():\n",
    "    for value in value_list:\n",
    "        if isinstance(value, str) and child_text in value:\n",
    "            found_key = key\n",
    "            break\n",
    "\n",
    "if found_key:\n",
    "    print(f\"Found match in '{found_key}' list.\")\n",
    "else:\n",
    "    print(\"No match found in any list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "022bc167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barjraj',\n",
       " 'ramdin verma',\n",
       " 'sharat chandran',\n",
       " 'birender mandal',\n",
       " 'amit',\n",
       " 'kushal',\n",
       " 'kasid',\n",
       " 'shiv prakash',\n",
       " 'vikram singh',\n",
       " 'sanjay',\n",
       " 'abhi',\n",
       " 'ram dutt gupta',\n",
       " 'khadak singh',\n",
       " 'gurmit singh',\n",
       " 'chanderpal',\n",
       " 'aman',\n",
       " 'khursid',\n",
       " 'rajeev',\n",
       " 'durgesh',\n",
       " 'nahar singh',\n",
       " 'ram kumar',\n",
       " 'sunder paal',\n",
       " 'maansingh aswal',\n",
       " 'rohit',\n",
       " 'rohit',\n",
       " 'sparsh',\n",
       " 'santosh',\n",
       " 'santosh',\n",
       " 'punit khandelwal',\n",
       " 'dinesh',\n",
       " 'gulshan',\n",
       " 'arvind kumar yadav',\n",
       " 'nausad',\n",
       " 'gurmit singh',\n",
       " 'md. afsar',\n",
       " 'shiv shakti singh',\n",
       " 'moti lal',\n",
       " 'kausal kumar',\n",
       " 'rohit',\n",
       " 'rohit',\n",
       " 'mohabbat ali',\n",
       " 'raj kumar',\n",
       " 'jaswant singh',\n",
       " 'sevak @ pitambar lal',\n",
       " 'chotelal',\n",
       " 'amit',\n",
       " 'rupesh',\n",
       " 'midda',\n",
       " 'dharam singh',\n",
       " 'manoj yadav @ manoj',\n",
       " 'ram singh',\n",
       " 'preetam kumar',\n",
       " 'ram kumar',\n",
       " 'sarain',\n",
       " 'pankaj kumar',\n",
       " 'sheak shakir',\n",
       " 'riyasat ali',\n",
       " 'vinit katariya',\n",
       " 'sumit',\n",
       " 'arindra',\n",
       " 'kali charan',\n",
       " 'badshya khan',\n",
       " 'vikash',\n",
       " 'devinder chadda',\n",
       " 'aman',\n",
       " 'mohan singh',\n",
       " 'hemant',\n",
       " 'shivam',\n",
       " 'yash mittal',\n",
       " 'aakash',\n",
       " 'chandesh',\n",
       " 'sumit mitra',\n",
       " 'supriyal sen',\n",
       " 'gajender singh @ goldy',\n",
       " 'pooran chand sharma',\n",
       " 'irfan',\n",
       " 'azaruddin',\n",
       " 'mukul yadav',\n",
       " 'pooran chand sharma',\n",
       " 'manoj',\n",
       " 'sanjay charee',\n",
       " 'raja babu',\n",
       " 'pawan',\n",
       " 'sandeep',\n",
       " 'rajkumar chawla',\n",
       " 'parvesh',\n",
       " 'mohd ataullah',\n",
       " 'neeraj kumar',\n",
       " 'jamil khan',\n",
       " 'yogita',\n",
       " 'rijul aggarwal',\n",
       " 'mohd shakib',\n",
       " 'rahul kumar',\n",
       " 'rajender',\n",
       " 'suraj',\n",
       " 'rizwan',\n",
       " 'sandeep',\n",
       " 'md mustafa',\n",
       " 'har parsad',\n",
       " 'deepak',\n",
       " 'rahul',\n",
       " 'abhishekh',\n",
       " 'shelender yadav',\n",
       " 'sanjay',\n",
       " 'ankit',\n",
       " 'mohd aakib',\n",
       " 'surender singh chauhan',\n",
       " 'amit',\n",
       " 'arjun',\n",
       " 'rahul sharma',\n",
       " 'keshar ansari',\n",
       " 'raju @ chhotu',\n",
       " 'kuldeep singh',\n",
       " 'santlal@golu',\n",
       " 'lalit rana',\n",
       " 'pulkit sharma',\n",
       " 'aman soni @ badal',\n",
       " 'jahoor ahmed meer',\n",
       " 'sumit',\n",
       " 'tammanne',\n",
       " 'kailash kumar',\n",
       " 'bhagwati prasad',\n",
       " 'ajay',\n",
       " 'silender',\n",
       " 'deepak',\n",
       " 'akhilesh',\n",
       " 'dipendra kumar',\n",
       " 'nitin',\n",
       " 'doodhnath pandit',\n",
       " 'aslam allam',\n",
       " 'rahul',\n",
       " 'jitender kumar',\n",
       " 'adnan',\n",
       " 'vijay',\n",
       " 'yogesh',\n",
       " 'kabir',\n",
       " 'sarvesh',\n",
       " 'rakesh sarkar',\n",
       " 'akash gupta',\n",
       " 'rahul',\n",
       " 'pintu thakur',\n",
       " 'vivek',\n",
       " 'mohd khairul',\n",
       " 'farmaan khan',\n",
       " 'vansu dev',\n",
       " 'vansu dev',\n",
       " 'shyam kumar',\n",
       " 'shafibul',\n",
       " 'lalit kathuriya',\n",
       " 'pooran chand',\n",
       " 'aamir hussain',\n",
       " 'kamal jit singh',\n",
       " 'shiv kumar',\n",
       " 'mayank chaudhary @ rahul',\n",
       " 'rohit',\n",
       " 'som dutt',\n",
       " 'bablu regar',\n",
       " 'rohit',\n",
       " 'rajkumar',\n",
       " 'mubarik',\n",
       " 'niraj',\n",
       " 'sarbjeet @ ronak',\n",
       " 'axat',\n",
       " 'amit',\n",
       " 'anubhav shrivastab',\n",
       " 'akkash',\n",
       " 'himanshu',\n",
       " 'harsh dagar',\n",
       " 'anil kumar',\n",
       " 'vijay virmani',\n",
       " 'vivek auhari',\n",
       " 'sachin',\n",
       " 'subhash chand bhatia',\n",
       " 'bhupender',\n",
       " 'raghunandan das',\n",
       " 'sanjay',\n",
       " 'ajay kumar',\n",
       " 'yognder',\n",
       " 'subhash',\n",
       " 'arun @ vicky',\n",
       " 'rahul',\n",
       " 'vikas',\n",
       " 'vinod',\n",
       " 'salman',\n",
       " 'mohan kumar',\n",
       " 'sandeep meghawal',\n",
       " 'imamudeen',\n",
       " 'sandeep kumar',\n",
       " 'tarjan',\n",
       " 'kuldeep singh',\n",
       " 'murari',\n",
       " 'ramvilash',\n",
       " 'jagdish',\n",
       " 'vishal @ moni',\n",
       " 'mohd shahid',\n",
       " 'ramvilash',\n",
       " 'kuldeep',\n",
       " 'talim',\n",
       " 'nanku prasad',\n",
       " 'bhola sarkar',\n",
       " 'balraj',\n",
       " 'ravindra kumar',\n",
       " 'rohit kumar',\n",
       " 'uttam kumar @ sanki',\n",
       " 'babalu sen',\n",
       " 'rustam shah',\n",
       " 'sukhdev',\n",
       " 'b vikjay kumar',\n",
       " 'dolly @ rekha w/o monto shah',\n",
       " 'gopal sharma',\n",
       " 'beeru',\n",
       " 'vipin',\n",
       " 'manish garg',\n",
       " 'guddu',\n",
       " 'jatin @ sonu',\n",
       " 'amit kumar',\n",
       " 'amit kumar',\n",
       " 'shadab',\n",
       " 'rakesh',\n",
       " 'guddu',\n",
       " 'abhishek',\n",
       " 'gulfam',\n",
       " 'phoolwati @ phoolo devi',\n",
       " 'mohit maan',\n",
       " 'veer bhan singh',\n",
       " 'dinesh kumar',\n",
       " 'amarjeet',\n",
       " 'satyadev',\n",
       " 'mohd. mukhtaar',\n",
       " 'rishi',\n",
       " 'esrail khan',\n",
       " 'suresh kumar',\n",
       " 'pankaj chand',\n",
       " 'ajay narayan',\n",
       " 'mohit @ himanshu',\n",
       " 'sumit',\n",
       " 'saddam',\n",
       " 'nikhleshwar bhagat',\n",
       " 'jai singh',\n",
       " 'deepak',\n",
       " 'sunil kumar',\n",
       " 'ram kishan',\n",
       " 'arun',\n",
       " 'virender',\n",
       " 'bishun',\n",
       " 'pritam singh',\n",
       " 'akash gupta',\n",
       " 'kishan',\n",
       " 'mohd kausar',\n",
       " 'sachin',\n",
       " 'harman singh',\n",
       " 'deepak',\n",
       " 'rajbir',\n",
       " 'vinod lal',\n",
       " nan,\n",
       " 'chander shaker',\n",
       " 'krishan',\n",
       " 'ram ji',\n",
       " 'jony',\n",
       " 'mohammad ali',\n",
       " 'ashok kumar s/o',\n",
       " 'ravinder @ bacchi',\n",
       " 'amit',\n",
       " 'guman singh basyal',\n",
       " 'amardeep',\n",
       " 'jagdish',\n",
       " 'bharat',\n",
       " 'azaz',\n",
       " 'raja kumar',\n",
       " 'parveen',\n",
       " 'mahabir prasad',\n",
       " 'kartik @ kaku',\n",
       " 'shubham yadav',\n",
       " 'yogesh',\n",
       " 'madan',\n",
       " 'rashid',\n",
       " 'jitender',\n",
       " 'pawan kumar',\n",
       " 'vivek',\n",
       " 'pintu kumar',\n",
       " 'deep',\n",
       " 'dharmbir',\n",
       " 'rishi kakdia',\n",
       " 'kunal @ kannu',\n",
       " 'arman ansari',\n",
       " 'avinsh',\n",
       " 'karan',\n",
       " 'sandeep kumar',\n",
       " 'sagar',\n",
       " 'nikhil',\n",
       " 'raman',\n",
       " 'sujen manjhi',\n",
       " 'abhijeet',\n",
       " 'anshu',\n",
       " 'sahil',\n",
       " 'aditya som',\n",
       " 'gaurav',\n",
       " 'raja kumar',\n",
       " 'sunil',\n",
       " 'ravi kumar',\n",
       " 'shankar kumar',\n",
       " 'vishvash',\n",
       " 'sonia',\n",
       " 'santosh',\n",
       " 'kayamuddin',\n",
       " 'rohit kumar',\n",
       " 'nandkishore karpenter',\n",
       " 'lala bhai',\n",
       " 'kishan rai',\n",
       " 'mahender kumar',\n",
       " 'deepak',\n",
       " 'mohd afzal',\n",
       " 'satender',\n",
       " 'shiv prasad singh',\n",
       " 'mobin',\n",
       " 'khokan sarkar',\n",
       " 'vikash',\n",
       " 'krisana braman',\n",
       " 'vipol',\n",
       " 'sanjay',\n",
       " 'mohd miraj ansari',\n",
       " 'rajmani',\n",
       " 'harbir  singh',\n",
       " 'mohan',\n",
       " 'farid',\n",
       " 'yuvraj kumar',\n",
       " 'charan jeet singh',\n",
       " 'satish kumar',\n",
       " 'gappu',\n",
       " 'nazeem',\n",
       " 'aamir',\n",
       " 'vivek sharma',\n",
       " 'sandeep',\n",
       " 'gutam',\n",
       " 'prakul',\n",
       " 'birjesh',\n",
       " 'sahil tigga',\n",
       " 'girishi chand',\n",
       " 'pavan sharma',\n",
       " 'ikramuddin',\n",
       " 'sajan',\n",
       " 'molu',\n",
       " 'dilawar',\n",
       " 'naval kishore',\n",
       " 'sanjay',\n",
       " 'ajahar',\n",
       " 'sanjeev',\n",
       " 'raman ralhan',\n",
       " 'raman ralhan',\n",
       " 'rohit',\n",
       " 'prem chand',\n",
       " 'sandhaya',\n",
       " 'ashish',\n",
       " 'irfan',\n",
       " 'jang bahadur',\n",
       " 'om parkash ahuja',\n",
       " 'kamre alam',\n",
       " 'md. raju',\n",
       " 'dinesh',\n",
       " 'satpal',\n",
       " 'ram pyare',\n",
       " 'suraj singh',\n",
       " 'ashfaq',\n",
       " 'shaid',\n",
       " 'vikas gupta',\n",
       " 'vijay singh',\n",
       " 'hari ram',\n",
       " 'manoj kumar',\n",
       " 'parash das',\n",
       " 'mehraj',\n",
       " 'chetan',\n",
       " 'bhanwar lal',\n",
       " 'sanavvar',\n",
       " 'rahul sharma',\n",
       " 'mustaq',\n",
       " 'ramkaran verma',\n",
       " 'mukhtyar hussain',\n",
       " 'vakil',\n",
       " 'bilal malik',\n",
       " 'radheshyam sen',\n",
       " 'mukesh',\n",
       " 'sunil kumar',\n",
       " 'sunny',\n",
       " 'jitender rajak',\n",
       " 'brahamprakash s/o meer singh',\n",
       " 'raju singh',\n",
       " 'sobit saini',\n",
       " 'inder dutt',\n",
       " 'shakir',\n",
       " 'haseen ahmed',\n",
       " 'kiran',\n",
       " 'gulam rashul',\n",
       " 'rajan',\n",
       " 'ayush',\n",
       " 'suraj',\n",
       " 'sehboob',\n",
       " 'sanjay kumar s/o',\n",
       " 'manish',\n",
       " 'amit kumar yadav',\n",
       " 'divaraj',\n",
       " 'kamlesh',\n",
       " 'rajiv bagoriya',\n",
       " 'abhinav chaudhary',\n",
       " 'rahul',\n",
       " 'devender singh s/o shrinath r/o kh. no. 72/1, utsa',\n",
       " 'azruddin',\n",
       " 'sanjay kumar @ pappu',\n",
       " 'mushir ahmed',\n",
       " 'vibhuti shyamal',\n",
       " 'inderjeet',\n",
       " 'sanjay',\n",
       " 'golu',\n",
       " 'lokesh',\n",
       " 'rajkumar',\n",
       " 'neeraj kandari',\n",
       " 'mukul verma',\n",
       " 'rijakpal',\n",
       " 'jai kishan',\n",
       " 'munna lal jain',\n",
       " 'jai prakash kashyap',\n",
       " 'jai prakash kashyap',\n",
       " 'shishram',\n",
       " 'parveen aggarwal',\n",
       " 'pramod paswan',\n",
       " 'ajit',\n",
       " 'deelip',\n",
       " 'deelip',\n",
       " 'rahul',\n",
       " 'aaftaab husan',\n",
       " 'monu',\n",
       " 'ramesh',\n",
       " 'sawan gupta',\n",
       " 'munna lal',\n",
       " 'saurabh',\n",
       " 'sarvesh kumar pandey',\n",
       " 'avdhesh',\n",
       " 'sohnal kumar singh',\n",
       " 'najar hussan',\n",
       " 'raman @ rancho',\n",
       " 'lavtar singh',\n",
       " 'nanak chand',\n",
       " 'harprasad sahu',\n",
       " 'vikas kumar',\n",
       " 'ashsish kumar',\n",
       " 'rajesh singh',\n",
       " 'ashu',\n",
       " 'manjeet',\n",
       " 'jaipal',\n",
       " 'jalil ansari',\n",
       " 'deepak verma',\n",
       " 'kasim',\n",
       " 'monu kumar',\n",
       " 'shankar kumar',\n",
       " 'manish kumar saket',\n",
       " 'vijay',\n",
       " 'udham',\n",
       " 'saurabh s/o',\n",
       " 'ayush',\n",
       " 'ravinder',\n",
       " 'rahul',\n",
       " 'narayan gadri',\n",
       " 'lakshman nath',\n",
       " 'rahul',\n",
       " 'rohit',\n",
       " 'ajay',\n",
       " 'sachin kumar',\n",
       " 'shahid',\n",
       " 'amarjeet',\n",
       " 'munna @ ravi jaiswal',\n",
       " 'ishtkar',\n",
       " 'harish chand',\n",
       " 'puneet jain',\n",
       " 'abhishekh',\n",
       " 'rashab',\n",
       " 'amit kumar shukla',\n",
       " 'vinod',\n",
       " 'praful naag',\n",
       " 'tarachand @ pappu',\n",
       " 'deepak rana',\n",
       " 'puran singh rastogi',\n",
       " 'narender',\n",
       " 'lal babu prasad',\n",
       " 'dinesh',\n",
       " 'rakesh',\n",
       " 'ankush',\n",
       " 'kuldeep',\n",
       " 'lal chand',\n",
       " 'vivek',\n",
       " 'pankaj',\n",
       " 'sanjay',\n",
       " 'kiran pal',\n",
       " 'ranveer singh',\n",
       " 'anwar',\n",
       " 'sadab urf golu',\n",
       " 'gorav',\n",
       " 'raj kumar @ raju',\n",
       " 'jitender',\n",
       " 'laxmikant @kaka',\n",
       " 'narayan parsad bhushal',\n",
       " 'abbas',\n",
       " 'avinash',\n",
       " 'ravish',\n",
       " 'hukum chand',\n",
       " 'pappu @ mahender singh',\n",
       " 'akash tomer',\n",
       " 'mahesh chand tiwari',\n",
       " 'rekhai',\n",
       " 'gajender kumar',\n",
       " 'vashudev',\n",
       " 'bhanwar singh',\n",
       " 'amit kumar',\n",
       " 'surender sain',\n",
       " 'akshay kumar',\n",
       " 'goldy',\n",
       " 'satyender @ kalu',\n",
       " 'devender',\n",
       " 'veer',\n",
       " 'ankush @ shera',\n",
       " 'mohd. amir',\n",
       " 'babloo',\n",
       " 'bhavesh dass',\n",
       " 'gourav',\n",
       " 'sunil',\n",
       " 'guddu rai',\n",
       " 'yogesh rawat',\n",
       " 'amarapal',\n",
       " 'rajesh agarwal',\n",
       " 'tara singh rawat',\n",
       " 'momin',\n",
       " 'parnav kumar',\n",
       " 'neeraj kumar',\n",
       " 'parminder',\n",
       " 'mustafa',\n",
       " 'ajay haldar',\n",
       " 'sanjay',\n",
       " 'dharmender',\n",
       " 'gaurav sethi',\n",
       " 'suresh',\n",
       " 'rohit',\n",
       " 'dinesh',\n",
       " 'sachin kumar',\n",
       " 'sagar',\n",
       " 'vipin',\n",
       " 'parth madan',\n",
       " 'kuldeep',\n",
       " 'abhimanyu',\n",
       " 'pawan kumar @ sonu',\n",
       " 'rohan',\n",
       " 'raju garg',\n",
       " 'samir mishra',\n",
       " 'ram dayal',\n",
       " 'jagdish chand',\n",
       " 'kanheya',\n",
       " 'deepak',\n",
       " 'mushrraf',\n",
       " 'prem',\n",
       " 'pardeep kumar',\n",
       " 'monu',\n",
       " 'pawan',\n",
       " 'manoj kumar',\n",
       " 'deepak',\n",
       " 'nithyanandham',\n",
       " 'deepak goyal',\n",
       " 'sunil ladkani',\n",
       " 'ajay',\n",
       " 'gopal',\n",
       " 'vivek',\n",
       " 'mahavir',\n",
       " 'indra sain',\n",
       " 'soni',\n",
       " 'arun kumar',\n",
       " 'ashok sharma',\n",
       " 'veer singh',\n",
       " 'aman dahiya',\n",
       " 'pawan',\n",
       " 'laxmi narayan',\n",
       " 'vikram dubey',\n",
       " 'rima',\n",
       " 'suraj',\n",
       " 'virender',\n",
       " 'tara singh rawat',\n",
       " 'ramjan khan',\n",
       " 'sunder',\n",
       " 'omparkash',\n",
       " 'saddam',\n",
       " 'alok tiwari',\n",
       " 'vude bhadur',\n",
       " 'prem singh bidla',\n",
       " 'chetanya swaroop',\n",
       " 'pinkoo @ guddu',\n",
       " 'shardanand',\n",
       " 'vikash',\n",
       " 'henkhochon haokip',\n",
       " 'gaurav shankar',\n",
       " 'shsi kant',\n",
       " 'md. tavrej',\n",
       " 'amrudin',\n",
       " 'shahnawaz',\n",
       " 'brij raj',\n",
       " 'aman kumar',\n",
       " 'dinesh',\n",
       " 'vijay kumar',\n",
       " 'baban @ suresh',\n",
       " 'subham kumar yadav',\n",
       " 'sapna',\n",
       " 'surendra',\n",
       " 'naveen',\n",
       " 'ram niwas',\n",
       " 'amar',\n",
       " 'nanhu khan',\n",
       " 'kishan',\n",
       " 'dharmender',\n",
       " 'raja ram',\n",
       " 'rishab',\n",
       " 'ziyabul',\n",
       " 'jag mohan',\n",
       " 'devender',\n",
       " 'ritu raj kumar',\n",
       " 'manoj kumar',\n",
       " 'raj kapoor',\n",
       " 'arvind agarwal @ pinto',\n",
       " 'rajbir ahlawat',\n",
       " 'mohd faijan',\n",
       " 'suraj',\n",
       " 'shyama',\n",
       " 'mohd. firoz',\n",
       " 'jagdish',\n",
       " 'bhag chand',\n",
       " 'sachin',\n",
       " 'parbhat',\n",
       " 'aamod & pramod',\n",
       " 'chander shekhar',\n",
       " 'nanagram',\n",
       " 'gautam',\n",
       " 'mohan',\n",
       " 'govind',\n",
       " 'raja babu',\n",
       " 'pramjot singh',\n",
       " 'abhinav vashit',\n",
       " 'usha',\n",
       " 'vivek chabra',\n",
       " 'ashish',\n",
       " 'ankit',\n",
       " 'harish chand',\n",
       " 'nootan prakash yadav',\n",
       " 'surender',\n",
       " 'chhotelal',\n",
       " 'karan',\n",
       " 'karan',\n",
       " 'abdul kadir',\n",
       " 'vikas kumar',\n",
       " 'sambhu',\n",
       " 'bablu',\n",
       " 'bablu',\n",
       " 'rajender @ kaku',\n",
       " 'ram ldaike',\n",
       " 'raju',\n",
       " 'yasib',\n",
       " 'sone lal shah',\n",
       " 'manoj kumar',\n",
       " 'chhotu harijan',\n",
       " 'sushant',\n",
       " 'om prakash',\n",
       " 'manish kumar',\n",
       " 'adersen',\n",
       " 'mukesh kumar yogi',\n",
       " 'ramesh',\n",
       " 'sagar',\n",
       " 'amit',\n",
       " 'gautam kumar',\n",
       " 'raj kumar',\n",
       " 'hardeep @ hunny',\n",
       " 'rohit kumar',\n",
       " 'himanshu',\n",
       " 'fitrat',\n",
       " 'pankaj saini',\n",
       " 'manish sehrawat',\n",
       " 'krishan',\n",
       " 'ravi chandra natarajan',\n",
       " 'karunakar dehra',\n",
       " 'somdath',\n",
       " 'shiva',\n",
       " 'rajeev jha',\n",
       " 'vishal',\n",
       " 'mukesh soni',\n",
       " 'ashok kharkwal',\n",
       " 'raj kumar',\n",
       " 'iswar sharan',\n",
       " 'maj- koko khaing',\n",
       " 'manni @ manish',\n",
       " 'sonu',\n",
       " 'amrit patel',\n",
       " 'tausin',\n",
       " 'rajveer',\n",
       " 'rupesh rathor',\n",
       " 'dinesh singh rana',\n",
       " 'bhrat narayn',\n",
       " 'annu',\n",
       " 'ombir singh',\n",
       " 'ombir singh',\n",
       " 'anand',\n",
       " 'rajesh kumar',\n",
       " 'varun chandela',\n",
       " 'rahul',\n",
       " 'yameen',\n",
       " 'ravi singh',\n",
       " 'jitendra singh',\n",
       " 'vivek',\n",
       " 'iarfan mohammad',\n",
       " 'raj kumar',\n",
       " 'mukesh',\n",
       " 'sahil',\n",
       " 'vasim',\n",
       " 'gaurav kumar',\n",
       " 'prateek kumar tiwari',\n",
       " 'birju',\n",
       " 'pradeep',\n",
       " 'raghubir singh',\n",
       " 'ayub khan',\n",
       " 'ram jatan',\n",
       " 'azhar  ali',\n",
       " 'tufail',\n",
       " 'parveen',\n",
       " 'afridi',\n",
       " 'tahir',\n",
       " 'ankit tiwari',\n",
       " 'ravi',\n",
       " 'abhay',\n",
       " 'anuj tiwari',\n",
       " 'vipiv malkania',\n",
       " 'inderpal',\n",
       " 'dinesh singh',\n",
       " 'suraj',\n",
       " 'sanjit misra',\n",
       " 'aasto',\n",
       " 'charan singh',\n",
       " 'dhansinghpuri',\n",
       " 'chottu shah',\n",
       " 'ram chander jha',\n",
       " 'arjun',\n",
       " 'nirmal',\n",
       " 'niranjan',\n",
       " 'mantu kumar',\n",
       " 'saurabh',\n",
       " 'firakat ali',\n",
       " 'ajay',\n",
       " 'sagar',\n",
       " 'ashshwer parsad',\n",
       " 'akash',\n",
       " 'andhav',\n",
       " 'akhil kumar',\n",
       " 'ranbir',\n",
       " 'amit',\n",
       " 'inderjeet mandal',\n",
       " 'sikandar',\n",
       " 'arjun singh',\n",
       " 'vishal mishra',\n",
       " 'dalip shah',\n",
       " 'mohd. jafruddin',\n",
       " 'satnosh',\n",
       " 'sohan lal',\n",
       " 'vinod kumar',\n",
       " 'dinesh singh',\n",
       " 'ajay kumar',\n",
       " 'pawan',\n",
       " 'aasish  kumar',\n",
       " 'tavinder kumar',\n",
       " 'laxman',\n",
       " 'milan',\n",
       " 'harishankar verma',\n",
       " 'rahul',\n",
       " 'manish',\n",
       " 'arun',\n",
       " 'sri kant',\n",
       " 'radheyshyam saini',\n",
       " 'mohit',\n",
       " 'damanjeet singh',\n",
       " 'sameer',\n",
       " 'bhushan sahay',\n",
       " 'ramesh kumar',\n",
       " 'samadh',\n",
       " 'malkeet singh',\n",
       " 'sachin',\n",
       " 'uma shankar',\n",
       " 'kamla prasad',\n",
       " 'mukesh',\n",
       " 'mohd. iqbal',\n",
       " 'sachin',\n",
       " 'tikku',\n",
       " 'deepak',\n",
       " 'vikash',\n",
       " 'janesh',\n",
       " 'satender',\n",
       " 'lakshya chauhan @ lucky',\n",
       " 'anoop singh',\n",
       " 'dal chand',\n",
       " 'pushpendra singh rathore',\n",
       " 'harpal singh',\n",
       " 'khimanand',\n",
       " 'manoj  kumar age-24 & satesh  kumar age 18',\n",
       " 'akshit',\n",
       " 'chandan kumar',\n",
       " 'vinay',\n",
       " 'pancham',\n",
       " 'ritu raj',\n",
       " 'vinay kumar upadhayay',\n",
       " 'shekher',\n",
       " 'vinod',\n",
       " 'abhishek yadav',\n",
       " 'abhishek yadav',\n",
       " 'manish khandelwal',\n",
       " 'bir singh',\n",
       " 'ram niwas',\n",
       " 'rajkumar saini s/o madan lal saini',\n",
       " 'rakesh',\n",
       " 'mohd sajim',\n",
       " 'shankarlal s/o sukharam',\n",
       " 'rahul sharma',\n",
       " 'neeraj kishore',\n",
       " 'ishwar',\n",
       " 'bilal',\n",
       " 'ravi parkash solanki',\n",
       " 'rohit kumar tiwari',\n",
       " 'pramod',\n",
       " 'manjeet kumar',\n",
       " 'vimal kumar',\n",
       " 'vijay',\n",
       " 'abbas mehndi',\n",
       " 'omprkash',\n",
       " 'deepak rathore',\n",
       " 'masoom',\n",
       " 'deepak kamat',\n",
       " 'ajay @ ajju',\n",
       " 'abhishek',\n",
       " 'toquir ali',\n",
       " 'shyam sundra',\n",
       " 'ankit',\n",
       " 'sarthak dadwal',\n",
       " 'armaan @ suvalin',\n",
       " 'kunal kishore',\n",
       " 'nabav shekh',\n",
       " 'kasim ansari',\n",
       " 'nitin parkash',\n",
       " 'deepak',\n",
       " 'subin sugathan',\n",
       " 'mayur agarwal',\n",
       " 'madan lal',\n",
       " 'vinay kumar',\n",
       " 'ghansyam soni',\n",
       " 'ram dutt',\n",
       " 'sanjeev sharma',\n",
       " 'devender singh',\n",
       " 'asharam',\n",
       " 'son pal@ sonu kumar',\n",
       " 'badri prsad mishra',\n",
       " 'azad ali',\n",
       " 'jorj vargees',\n",
       " 'naresh adhikari',\n",
       " 'deepu',\n",
       " 'pawan singh',\n",
       " 'aashik',\n",
       " 'amit kumar verma',\n",
       " 'subham @ vikash',\n",
       " 'sugodh kumar',\n",
       " 'ashok',\n",
       " 'satish',\n",
       " 'sanjeev',\n",
       " 'munender singh',\n",
       " 'krishan kumar',\n",
       " 'suraj',\n",
       " 'ashutosh @ deepak',\n",
       " 'rajkumar',\n",
       " 'saddam hussain',\n",
       " 'harender',\n",
       " 'jay kumar',\n",
       " 'mohd imran @ munna',\n",
       " 'amit',\n",
       " 'shyam sunder',\n",
       " 'parmod',\n",
       " 'mangat singh',\n",
       " 'sanjeev',\n",
       " 'aryan prateek',\n",
       " 'rahul chauhan',\n",
       " 'savan',\n",
       " 'mohd siwam',\n",
       " 'aarif',\n",
       " 'rajender kumar',\n",
       " 'dinesh',\n",
       " 'manish @ mukesh',\n",
       " 'ramesh singh negi',\n",
       " 'patik@monu',\n",
       " 'nand kishor',\n",
       " 'rajeev luka',\n",
       " 'sarad raghuvansi',\n",
       " 'ram prakash',\n",
       " 'sh pratap singh',\n",
       " 'liyakat ali',\n",
       " 'vicky',\n",
       " 'bodh raj @kala',\n",
       " 'pankaj ratori',\n",
       " 'leela dhar narang',\n",
       " 'devender',\n",
       " 'chanchal',\n",
       " 'abdul rehman',\n",
       " 'shamshad',\n",
       " 'bittu paswan',\n",
       " 'shashank sharma',\n",
       " 'hare chatiyan',\n",
       " 'deepak',\n",
       " 'vipulander',\n",
       " 'yogesh',\n",
       " 'abdul rahman',\n",
       " 'raju',\n",
       " 'khuma ram',\n",
       " 'naresh chand @ pappu',\n",
       " 'saurabh',\n",
       " 'komal / kabila',\n",
       " 'vikash @ mungeri',\n",
       " 'deepak kumar mishra',\n",
       " 'piyush',\n",
       " 'lakhan',\n",
       " 'nadim',\n",
       " 'sahdab',\n",
       " 'deepak',\n",
       " 'tufel',\n",
       " 'tekchand',\n",
       " 'ravi kumar',\n",
       " 'bobby',\n",
       " 'pankaj',\n",
       " 'amit kumar',\n",
       " 'tejvir',\n",
       " 'sachin kumar',\n",
       " 'dilip',\n",
       " 'ravi shankar',\n",
       " 'deepak',\n",
       " 'subodh',\n",
       " 'pramood',\n",
       " 'dev',\n",
       " 'devender',\n",
       " 'suresh@tinku',\n",
       " 'shri kant',\n",
       " 'om parkash',\n",
       " 'muntiyaj',\n",
       " 'raja kumar',\n",
       " 'chetan pandey',\n",
       " 'lilu',\n",
       " 'surjeet',\n",
       " 'dev',\n",
       " 'raju',\n",
       " 'sunder lal',\n",
       " 'aman bhatt',\n",
       " 'ratikant maghi',\n",
       " 'anil kumar',\n",
       " 'deva',\n",
       " 'firoz',\n",
       " 'rahul',\n",
       " 'dr. hema hari pago',\n",
       " 'raghuveer',\n",
       " 'dheeraj',\n",
       " 'sardar sarbjeet singh',\n",
       " 'raman sharma',\n",
       " 'lalit rastogi',\n",
       " 'sita ram',\n",
       " 'dharmbir singh',\n",
       " 'krishan',\n",
       " 'ritik',\n",
       " 'ketan',\n",
       " 'angreg singh',\n",
       " 'dinesh',\n",
       " 'sitaram bairwa',\n",
       " 'rampati',\n",
       " 'rahul',\n",
       " 'karan bajaj',\n",
       " 'abhishek',\n",
       " 'ramsurat',\n",
       " 'jitendra kumar',\n",
       " 'sanjeev',\n",
       " 'lalit kumar',\n",
       " 'jockyipai',\n",
       " 'aslam ali',\n",
       " 'suraj kumar',\n",
       " 'jitender',\n",
       " 'murli dhar',\n",
       " 'rehman khan',\n",
       " 'gurdarshan singh',\n",
       " 'ramsem',\n",
       " 'shahrukh',\n",
       " 'krishan gopal',\n",
       " 'aakash',\n",
       " 'pardeep kumar',\n",
       " 'atul kumar',\n",
       " 'laxman',\n",
       " 'shanwaz anwar',\n",
       " 'samsuddin',\n",
       " 'jyoti prakash',\n",
       " 'ankit',\n",
       " 'sagar',\n",
       " 'sourav @ sumit',\n",
       " 'chain singh @ ravi',\n",
       " 'ravi @ rinkku',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gazette['names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1f28d",
   "metadata": {},
   "source": [
    "# gazette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1aa2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Akash Verma\n",
      "1\n",
      "New Delhi, Delhi\n",
      "2\n",
      "-Email me on Indeed: http://www.indeed.com/r/Akash-Verma/848734e32bf98980\n",
      "3\n",
      "Software Engineer with around 3 years of experience in building software and team collaboration, seeking full-timeÂ Software Engineer roles.\n",
      "4\n",
      "Work Experience\n",
      "5\n",
      "Software Engineer\n",
      "6\n",
      "Incedo Inc\n",
      "7\n",
      "July 2020 to Present\n",
      "8\n",
      "I created 3 projects in my current company using python. I'm currently working on 4th project. These projects are namely hardware diagnostic tool, thermal tool, certification tool, manufacturing tool.\n",
      "9\n",
      "Software Engineer\n",
      "10\n",
      "Endovision - Delhi, Delhi\n",
      "11\n",
      "Present\n",
      "12\n",
      "Education\n",
      "13\n",
      "Bachelor's in Computer Science & Engineering\n",
      "14\n",
      "Ajay Kumar Garg Engineering College, Ghaziabad - Ghaziabad, Uttar Pradesh\n",
      "15\n",
      "August 2016 to October 2020\n",
      "16\n",
      "Skills / IT Skills\n",
      "17\n",
      "â€¢ MYSQL\n",
      "18\n",
      "â€¢ Python\n",
      "19\n",
      "â€¢ Data structures\n",
      "20\n",
      "â€¢ MongoDB\n",
      "21\n",
      "â€¢ Docker\n",
      "22\n",
      "â€¢ Git\n",
      "23\n",
      "â€¢ Linux\n",
      "24\n",
      "â€¢ Ansible\n",
      "25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text = 'Akash Verma\\nNew Delhi, Delhi\\n-Email me on Indeed: http://www.indeed.com/r/Akash-Verma/848734e32bf98980\\nSoftware Engineer with around 3 years of experience in building software and team collaboration,\\nseeking full-timeÂ\\xa0\\nSoftware Engineer roles.'\n",
    "sentences = text.split('\\n')\n",
    "sentences = [sentence.strip() for sentence in sentences]\n",
    "\n",
    "result = []\n",
    "\n",
    "# Iterate through the sentences\n",
    "i = 0\n",
    "while i < len(sentences):\n",
    "    current_sentence = sentences[i].strip()\n",
    "    # Check if the current sentence length is 95 or more and doesn't end with a full stop\n",
    "    while len(current_sentence) >= 95 and not current_sentence.endswith('.'):\n",
    "        # Check if the next line exists\n",
    "        if i + 1 < len(sentences):\n",
    "            next_sentence = sentences[i + 1].strip()\n",
    "            # Append the next line to the current sentence\n",
    "            current_sentence += ' ' + next_sentence\n",
    "            # Move to the next sentence (skip the appended sentence)\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    # Append the modified or unmodified sentence to the result\n",
    "    result.append(current_sentence)\n",
    "    i += 1\n",
    "\n",
    "i=0\n",
    "for sentence in result:\n",
    "    print(i)\n",
    "    i=i+1\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f9c4b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ROOT><SENT><DNP_Akash><><PROPN>Akash</PROPN></></DNP_Akash><DNP_Verma><><PROPN>Akash</PROPN></><><PROPN>Verma</PROPN></></DNP_Verma></SENT><SENT><DNP_New><GPE><GZ_city><PROPN>New</PROPN></GZ_city></GPE></DNP_New><DNP_Delhi><GPE><GZ_city><PROPN>New</PROPN></GZ_city></GPE><GPE><GZ_city><PROPN>Delhi</PROPN></GZ_city></GPE><><PUNCT>,</PUNCT></><GPE><GZ_city><PROPN>Delhi</PROPN></GZ_city></GPE></DNP_Delhi></SENT><SENT><DVP_-Email><><VERB>-Email</VERB></><dobj_-Email><><PRON>me</PRON></></dobj_-Email><prep_on_-Email /><><ADP>on</ADP></><><ADV>Indeed</ADV></><><PUNCT>:</PUNCT></><><X>http://www.indeed.com/r/Akash-Verma/848734e32bf98980</X></></prep_on_-Email /></prep_in_Engineer /></DVP_-Email></SENT><SENT><DNP_Software><PERSON><PROPN>Software</PROPN></PERSON></DNP_Software><DNP_Engineer><PERSON><PROPN>Software</PROPN></PERSON><nsubj_Engineer><PERSON><PROPN>Engineer</PROPN></PERSON></nsubj_Engineer><prep_with_Engineer /><><ADP>with</ADP></><DATE><ADP>around</ADP></DATE><DATE><NUM>3</NUM></DATE><DATE><GZ_names><NOUN>years</NOUN></GZ_names></DATE></prep_with_Engineer /><prep_of_Engineer /><><ADP>of</ADP></><><GZ_company><NOUN>experience</NOUN></GZ_company></></prep_of_Engineer /><prep_in_Engineer /><><ADP>in</ADP></><><VERB>building</VERB></><><GZ_company><NOUN>software</NOUN></GZ_company></><><CCONJ>and</CCONJ></><><GZ_company><NOUN>team</NOUN></GZ_company></><dobj_Engineer><><GZ_company><NOUN>collaboration</NOUN></GZ_company></></dobj_Engineer><><PUNCT>,</PUNCT></></DNP_Engineer><DVP_seeking><PERSON><PROPN>Software</PROPN></PERSON><nsubj_seeking><PERSON><PROPN>Engineer</PROPN></PERSON></nsubj_seeking><prep_with_seeking /><><ADP>with</ADP></><DATE><ADP>around</ADP></DATE><DATE><NUM>3</NUM></DATE><DATE><GZ_names><NOUN>years</NOUN></GZ_names></DATE></prep_with_seeking /><prep_of_seeking /><><ADP>of</ADP></><><GZ_company><NOUN>experience</NOUN></GZ_company></></prep_of_seeking /><prep_in_seeking /><><ADP>in</ADP></><><VERB>building</VERB></><><GZ_company><NOUN>software</NOUN></GZ_company></><><CCONJ>and</CCONJ></><><GZ_company><NOUN>team</NOUN></GZ_company></><dobj_seeking><><GZ_company><NOUN>collaboration</NOUN></GZ_company></></dobj_seeking><><PUNCT>,</PUNCT></><><VERB>seeking</VERB></><><ADJ>full</ADJ></><><PUNCT>-</PUNCT></><><PROPN>timeÂ</PROPN></><><PROPN>Software</PROPN></><><PROPN>Engineer</PROPN></><dobj_seeking><><GZ_company><NOUN>roles</NOUN></GZ_company></></dobj_seeking><><PUNCT>.</PUNCT></></prep_in_seeking /></DVP_seeking></SENT><SENT><DVP_Work><><VERB>Work</VERB></></prep_to_July /></DVP_Work><DNP_Experience><><VERB>Work</VERB></><><NOUN>Experience</NOUN></></DNP_Experience></SENT><SENT><DNP_Software><><PROPN>Software</PROPN></></DNP_Software><DNP_Engineer><><PROPN>Software</PROPN></><><PROPN>Engineer</PROPN></></DNP_Engineer></SENT><SENT><DNP_Incedo><ORG><PROPN>Incedo</PROPN></ORG></DNP_Incedo><DNP_Inc><ORG><PROPN>Incedo</PROPN></ORG><ORG><GZ_city><PROPN>Inc</PROPN></GZ_city></ORG></DNP_Inc></SENT><SENT><DNP_July><DATE><PROPN>July</PROPN></DATE><DATE><NUM>2020</NUM></DATE><prep_to_July /><><ADP>to</ADP></><><VERB>Present</VERB></></DNP_July></SENT><SENT><DVP_created><nsubj_created><><PRON>I</PRON></></nsubj_created><><VERB>created</VERB></><CARDINAL><NUM>3</NUM></CARDINAL><dobj_created><><GZ_company><NOUN>projects</NOUN></GZ_company></></dobj_created><prep_in_created /><><ADP>in</ADP></><><PRON>my</PRON></><><ADJ>current</ADJ></><><GZ_company><NOUN>company</NOUN></GZ_company></><><VERB>using</VERB></><dobj_created><><GZ_company><NOUN>python</NOUN></GZ_company></></dobj_created><><PUNCT>.</PUNCT></></prep_in_created /></DVP_created><DVP_working><nsubj_working><><PRON>I</PRON></></nsubj_working><><AUX>'m</AUX></><><ADV>currently</ADV></><><VERB>working</VERB></><prep_on_working /><><ADP>on</ADP></><ORDINAL><ADJ>4th</ADJ></ORDINAL><><GZ_company><NOUN>project</NOUN></GZ_company></><><PUNCT>.</PUNCT></></prep_on_working /></DVP_working><DNP_projects><><DET>These</DET></><nsubj_projects><><GZ_company><NOUN>projects</NOUN></GZ_company></></nsubj_projects></DNP_projects><><GZ_company><NOUN>projects</NOUN></GZ_company></><><GZ_company><NOUN>projects</NOUN></GZ_company></><DNP_hardware><><GZ_company><NOUN>hardware</NOUN></GZ_company></></DNP_hardware><DNP_tool><><GZ_company><NOUN>hardware</NOUN></GZ_company></><><ADJ>diagnostic</ADJ></><><GZ_names><NOUN>tool</NOUN></GZ_names></><><PUNCT>,</PUNCT></><><ADJ>thermal</ADJ></><><GZ_names><NOUN>tool</NOUN></GZ_names></><><PUNCT>,</PUNCT></><><GZ_company><NOUN>certification</NOUN></GZ_company></><><GZ_names><NOUN>tool</NOUN></GZ_names></><><PUNCT>,</PUNCT></><><VERB>manufacturing</VERB></><><GZ_names><NOUN>tool</NOUN></GZ_names></></DNP_tool><><GZ_names><NOUN>tool</NOUN></GZ_names></></SENT><SENT><DNP_Software><><PROPN>Software</PROPN></></DNP_Software><DNP_Engineer><><PROPN>Software</PROPN></><><PROPN>Engineer</PROPN></></DNP_Engineer></SENT><SENT><DNP_Endovision><><PROPN>Endovision</PROPN></></DNP_Endovision><DNP_Delhi><><PROPN>Endovision</PROPN></><><PUNCT>-</PUNCT></><><GZ_city><PROPN>Delhi</PROPN></GZ_city></><><PUNCT>,</PUNCT></><GPE><GZ_city><PROPN>Delhi</PROPN></GZ_city></GPE></DNP_Delhi></SENT><SENT><DVP_Present><><VERB>Present</VERB></></prep_in_Bachelor /></prep_to_August /></DVP_Present></SENT><SENT><DNP_Education><><NOUN>Education</NOUN></></DNP_Education></SENT><SENT><DNP_Bachelor><ORG><PROPN>Bachelor</PROPN></ORG><><PART>'s</PART></><prep_in_Bachelor /><><ADP>in</ADP></><ORG><PROPN>Computer</PROPN></ORG><ORG><GZ_city><PROPN>Science</PROPN></GZ_city></ORG><ORG><CCONJ>&amp;</CCONJ></ORG><ORG><PROPN>Engineering</PROPN></ORG></DNP_Bachelor></SENT><SENT><DNP_Ajay><PERSON><PROPN>Ajay</PROPN></PERSON></DNP_Ajay><DNP_Kumar><PERSON><GZ_city><PROPN>Kumar</PROPN></GZ_city></PERSON></DNP_Kumar><DNP_Garg><ORG><GZ_city><PROPN>Garg</PROPN></GZ_city></ORG></DNP_Garg><DNP_Engineering><ORG><PROPN>Engineering</PROPN></ORG></DNP_Engineering><DNP_College><PERSON><PROPN>Ajay</PROPN></PERSON><PERSON><GZ_city><PROPN>Kumar</PROPN></GZ_city></PERSON><ORG><GZ_city><PROPN>Garg</PROPN></GZ_city></ORG><ORG><PROPN>Engineering</PROPN></ORG><ORG><GZ_city><PROPN>College</PROPN></GZ_city></ORG><><PUNCT>,</PUNCT></><GPE><PROPN>Ghaziabad</PROPN></GPE><><PUNCT>-</PUNCT></><GPE><PROPN>Ghaziabad</PROPN></GPE><><PUNCT>,</PUNCT></><GPE><GZ_city><PROPN>Uttar</PROPN></GZ_city></GPE><><PROPN>Pradesh</PROPN></></DNP_College></SENT><SENT><DNP_August><DATE><GZ_city><PROPN>August</PROPN></GZ_city></DATE><DATE><NUM>2016</NUM></DATE><prep_to_August /><DATE><ADP>to</ADP></DATE><DATE><PROPN>October</PROPN></DATE><DATE><NUM>2020</NUM></DATE></DNP_August></SENT><SENT><DNP_Skills><><NOUN>Skills</NOUN></></DNP_Skills><DNP_Skills><><NOUN>Skills</NOUN></><><SYM>/</SYM></><><PROPN>IT</PROPN></><><NOUN>Skills</NOUN></></DNP_Skills></SENT><SENT><DNP_MYSQL><PRODUCT><PUNCT>â€¢</PUNCT></PRODUCT><><PROPN>MYSQL</PROPN></></DNP_MYSQL></SENT><SENT><DNP_Python><><PUNCT>â€¢</PUNCT></><><PROPN>Python</PROPN></></DNP_Python></SENT><SENT><DNP_structures><PRODUCT><PUNCT>â€¢</PUNCT></PRODUCT><PRODUCT><GZ_city><NOUN>Data</NOUN></GZ_city></PRODUCT><><GZ_company><NOUN>structures</NOUN></GZ_company></></DNP_structures></SENT><SENT><PRODUCT><GZ_company><NOUN>structures</NOUN></GZ_company></PRODUCT></SENT><SENT><DNP_Docker><PRODUCT><PUNCT>â€¢</PUNCT></PRODUCT><PRODUCT><PROPN>Docker</PROPN></PRODUCT></DNP_Docker></SENT><SENT><DNP_Git><><PUNCT>â€¢</PUNCT></><><GZ_city><PROPN>Git</PROPN></GZ_city></></DNP_Git></SENT><SENT><DNP_Linux><PERSON><PUNCT>â€¢</PUNCT></PERSON><PERSON><PROPN>Linux</PROPN></PERSON></DNP_Linux></SENT><SENT><DNP_Ansible><PRODUCT><PUNCT>â€¢</PUNCT></PRODUCT><PRODUCT><PROPN>Ansible</PROPN></PRODUCT></DNP_Ansible></SENT><SENT /></ROOT>\n"
     ]
    }
   ],
   "source": [
    "# text1=\"Nikhil and barjraj are working in Sudha Co-operative Urban Bank Ltd as an Officer from Sep 2015 to till now. I have also worked in HDFC Bank since 2006 to 2015 in Mumbai, Pune and Hyderabad branches.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Create the root element\n",
    "root = ET.Element(\"ROOT\")\n",
    "    \n",
    "for sentence in result:\n",
    "    sentence_element = ET.SubElement(root, \"SENT\")\n",
    "    subtree_tokens = set()\n",
    "    doc= nlp(sentence)\n",
    "    \n",
    "    # Iterate over each token in the sentence\n",
    "    for token in list(doc):\n",
    "        if token in subtree_tokens:\n",
    "            continue\n",
    "    \n",
    "        parent = token\n",
    "    \n",
    "        while parent and parent!=parent.head and parent.pos_ not in [\"NOUN\", \"PROPN\", \"VERB\"]:\n",
    "            parent = parent.head\n",
    "        subtree_tokens.add(parent)\n",
    "        \n",
    "        if parent.pos_ == \"VERB\":\n",
    "            verb_subtree_element = ET.SubElement(sentence_element, f\"DVP_{parent.text}\")\n",
    "            prep_started = False\n",
    "            prep_word= None\n",
    "        \n",
    "            for child in parent.subtree:\n",
    "                subtree_tokens.add(child)\n",
    "            \n",
    "                if child.dep_==\"prep\":\n",
    "                    if prep_started:\n",
    "                        prep_subtree_element = ET.Element(f\"/prep_{prep_word}_{parent.text}\")\n",
    "                        verb_subtree_element.append(prep_subtree_element)\n",
    "                        prep_word=None\n",
    "                    prep_started = True\n",
    "                    prep_subtree_element = ET.Element(f\"prep_{child.text}_{parent.text}\")\n",
    "                    verb_subtree_element.append(prep_subtree_element)\n",
    "                    prep_word=child.text\n",
    "            \n",
    "                if child.dep_ in [\"nsubj\", \"dobj\", \"nsubjpass\"]:\n",
    "                    # Encapsulate the entire dependency subtree rooted at the child\n",
    "                    subtree_element_depverb = ET.SubElement(verb_subtree_element, f\"{child.dep_}_{parent.text}\")\n",
    "        \n",
    "                    # Create a token element\n",
    "                    token_element_ner = ET.SubElement(subtree_element_depverb, child.ent_type_)\n",
    "                \n",
    "                    found_key = None\n",
    "                    # Iterate through the dictionary values\n",
    "                    if child.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "                        for key, value_list in gazette.items():\n",
    "                            for value in value_list:\n",
    "                                if isinstance(value, str) and child.text in value:\n",
    "                                    found_key = key\n",
    "                                    break\n",
    "                    if found_key:\n",
    "                        token_element_gt = ET.SubElement(token_element_ner,f\"GZ_{found_key}\")\n",
    "                        # Create a token element\n",
    "                        token_element_pos = ET.SubElement(token_element_gt, child.pos_)\n",
    "                        token_element_pos.text = str(child.text)\n",
    "                    else:\n",
    "                        # Create a token element\n",
    "                        token_element_pos = ET.SubElement(token_element_ner, child.pos_)\n",
    "                        token_element_pos.text = str(child.text)\n",
    "                else:\n",
    "                    if child.pos_==\"SPACE\" and prep_started:\n",
    "                        prep_subtree_element = ET.Element(f\"/prep_{prep_word}_{parent.text}\")\n",
    "                        verb_subtree_element.append(prep_subtree_element)\n",
    "                        prep_word=None\n",
    "                        prep_started=False\n",
    "                    \n",
    "                    # Create a token element\n",
    "                    token_element_ner = ET.SubElement(verb_subtree_element, child.ent_type_)\n",
    "                    found_key = None\n",
    "                    # Iterate through the dictionary values\n",
    "                    if child.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "                        for key, value_list in gazette.items():\n",
    "                            for value in value_list:\n",
    "                                if isinstance(value, str) and child.text in value:\n",
    "                                    found_key = key\n",
    "                                    break\n",
    "                    if found_key :\n",
    "                        token_element_gt = ET.SubElement(token_element_ner,f\"GZ_{found_key}\")\n",
    "                        # Create a token element\n",
    "                        token_element_pos = ET.SubElement(token_element_gt, child.pos_)\n",
    "                        token_element_pos.text = str(child.text)\n",
    "                    else:\n",
    "                        # Create a token element\n",
    "                        token_element_pos = ET.SubElement(token_element_ner, child.pos_)\n",
    "                        token_element_pos.text = str(child.text)\n",
    "        \n",
    "            if prep_started:\n",
    "                prep_subtree_element = ET.Element(f\"/prep_{prep_word}_{parent.text}\")\n",
    "                verb_subtree_element.append(prep_subtree_element)\n",
    "                prep_word=None\n",
    "                prep_started=False\n",
    "                    \n",
    "        elif parent.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "            noun_subtree_element = ET.SubElement(sentence_element, f\"DNP_{parent.text}\")\n",
    "            prep_started = False\n",
    "            prep_word= None\n",
    "        \n",
    "            for child in parent.subtree:\n",
    "                subtree_tokens.add(child)\n",
    "            \n",
    "                if child.dep_==\"prep\":\n",
    "                    if prep_started:\n",
    "                        prep_subtree_element = ET.Element(f\"/prep_{prep_word}_{parent.text}\")\n",
    "                        noun_subtree_element.append(prep_subtree_element)\n",
    "                        prep_word=None\n",
    "                    prep_started = True\n",
    "                    prep_subtree_element = ET.Element(f\"prep_{child.text}_{parent.text}\")\n",
    "                    noun_subtree_element.append(prep_subtree_element)\n",
    "                    prep_word=child.text\n",
    "            \n",
    "                if child.dep_ in [\"nsubj\", \"dobj\", \"nsubjpass\"]:\n",
    "                    # Encapsulate the entire dependency subtree rooted at the child\n",
    "                    subtree_element_depverb = ET.SubElement(noun_subtree_element, f\"{child.dep_}_{parent.text}\")\n",
    "        \n",
    "                    # Create a token element\n",
    "                    token_element_ner = ET.SubElement(subtree_element_depverb, child.ent_type_)\n",
    "                    found_key = None\n",
    "                    # Iterate through the dictionary values\n",
    "                    if child.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "                        for key, value_list in gazette.items():\n",
    "                            for value in value_list:\n",
    "                                if isinstance(value, str) and child.text in value:\n",
    "                                    found_key = key\n",
    "                                    break\n",
    "                    if found_key:\n",
    "                        token_element_gt = ET.SubElement(token_element_ner,f\"GZ_{found_key}\")\n",
    "                        # Create a token element\n",
    "                        token_element_pos = ET.SubElement(token_element_gt, child.pos_)\n",
    "                        token_element_pos.text = str(child.text)\n",
    "                    else:\n",
    "                        # Create a token element\n",
    "                        token_element_pos = ET.SubElement(token_element_ner, child.pos_)\n",
    "                        token_element_pos.text = str(child.text)\n",
    "                else:\n",
    "                    if child.pos_==\"SPACE\" and prep_started:\n",
    "                        prep_subtree_element = ET.Element(f\"/prep_{prep_word}_{parent.text}\")\n",
    "                        verb_subtree_element.append(prep_subtree_element)\n",
    "                        prep_word=None\n",
    "                        prep_started=False\n",
    "                    \n",
    "                    # Create a token element\n",
    "                    token_element_ner = ET.SubElement(noun_subtree_element, child.ent_type_)\n",
    "                    found_key = None\n",
    "                    # Iterate through the dictionary values\n",
    "                    if child.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "                        for key, value_list in gazette.items():\n",
    "                            for value in value_list:\n",
    "                                if isinstance(value, str) and child.text in value:\n",
    "                                    found_key = key\n",
    "                                    break\n",
    "                    if found_key:\n",
    "                        token_element_gt = ET.SubElement(token_element_ner,f\"GZ_{found_key}\")\n",
    "                        # Create a token element\n",
    "                        token_element_pos = ET.SubElement(token_element_gt, child.pos_)\n",
    "                        token_element_pos.text = str(child.text)\n",
    "                    else:\n",
    "                        # Create a token element\n",
    "                        token_element_pos = ET.SubElement(token_element_ner, child.pos_)\n",
    "                        token_element_pos.text = str(child.text)\n",
    "                \n",
    "            if prep_started:\n",
    "                prep_subtree_element = ET.Element(f\"/prep_{prep_word}_{parent.text}\")\n",
    "                verb_subtree_element.append(prep_subtree_element)\n",
    "                prep_word=None\n",
    "                prep_started=False\n",
    "        else:\n",
    "            subtree_tokens.add(token)\n",
    "            # Create a token element\n",
    "            token_element_ner = ET.SubElement(sentence_element, token.ent_type_)\n",
    "        \n",
    "            found_key = None\n",
    "            # Iterate through the dictionary values\n",
    "            if child.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "                for key, value_list in gazette.items():\n",
    "                    for value in value_list:\n",
    "                        if isinstance(value, str) and child.text in value:\n",
    "                            found_key = key\n",
    "                            break\n",
    "            if found_key:\n",
    "                token_element_gt = ET.SubElement(token_element_ner, f\"GZ_{found_key}\")\n",
    "                # Create a token element\n",
    "                token_element_pos = ET.SubElement(token_element_gt, child.pos_)\n",
    "                token_element_pos.text = str(child.text)\n",
    "            else:\n",
    "                # Create a token element\n",
    "                token_element_pos = ET.SubElement(token_element_ner, child.pos_)\n",
    "                token_element_pos.text = str(child.text)\n",
    "\n",
    "# Convert the XML tree to a string\n",
    "xml_string = ET.tostring(root, encoding=\"unicode\")\n",
    "\n",
    "# Print or save the XML string\n",
    "print(xml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e499fdb",
   "metadata": {},
   "source": [
    "# rule-based matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43891a34",
   "metadata": {},
   "source": [
    "# person names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ab0d083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years\n",
      "Pradesh\n",
      "MYSQL\n",
      "IT\n",
      "Akash\n",
      "Endovision\n",
      "October\n",
      "Linux\n",
      "Engineering\n",
      "Ghaziabad\n",
      "Engineer\n",
      "Ajay\n",
      "Computer\n",
      "July\n",
      "Docker\n",
      "Python\n",
      "Software\n",
      "tool\n",
      "August\n",
      "Inc\n",
      "Kumar\n",
      "Incedo\n",
      "Delhi\n",
      "Git\n",
      "Uttar\n",
      "New\n",
      "College\n",
      "Science\n",
      "Bachelor\n",
      "Ansible\n",
      "Verma\n",
      "Garg\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Extract text inside <DNP> tags\n",
    "dnps = re.findall(r\"<DNP_.*?>(.*?)</DNP_.*?>\", xml_string, flags=re.DOTALL)\n",
    "\n",
    "matches=[]\n",
    "\n",
    "# Print the extracted text inside <DNP> tags\n",
    "for dnp in dnps:\n",
    "    # Extract text inside <PROPN> and <PERSON><PROPN> tags\n",
    "    persons = re.findall(r\"<PERSON><PROPN>(.*?)</PROPN></PERSON>\", dnp)\n",
    "    propn=re.findall(r\"<PROPN>(.*?)</PROPN>\", dnp)\n",
    "    gazette=re.findall(r\"<GZ_names>(.*?)</GZ_names>\", dnp)\n",
    "    \n",
    "    matches= matches+persons+propn+gazette\n",
    "    \n",
    "matches = list(set(matches))   \n",
    "# Print the extracted text\n",
    "if matches:\n",
    "    for match in matches :\n",
    "        pattern =  r'<[^<>]+?>'\n",
    "        clean_text = re.sub(pattern, '', match).replace('<>', '')\n",
    "        print(clean_text)\n",
    "else:\n",
    "    print(\"No matches found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b1b3e",
   "metadata": {},
   "source": [
    "# organization names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db59da2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftwareEngineer\n",
      "July2020toPresent\n",
      "AkashVerma\n",
      "Software\n",
      "Bachelor'sinComputerScience&amp;Engineering\n",
      "hardwarediagnostictool,thermaltool,certificationtool,manufacturingtool\n",
      "Software\n",
      "Garg\n",
      "WorkExperience\n",
      "Endovision-Delhi,Delhi\n",
      "Ajay\n",
      "Endovision\n",
      "New\n",
      "NewDelhi,Delhi\n",
      "Akash\n",
      "Incedo\n",
      "SoftwareEngineerwitharound3yearsofexperienceinbuildingsoftwareandteamcollaboration,\n",
      "IncedoInc\n",
      "AjayKumarGargEngineeringCollege,Ghaziabad-Ghaziabad,UttarPradesh\n",
      "Theseprojects\n",
      "Kumar\n",
      "Engineering\n",
      "hardware\n",
      "Education\n"
     ]
    }
   ],
   "source": [
    "org = re.findall(r\"<DNP_.*?>(?=.*?<ORG><PROPN>.*?</PROPN></ORG>)(.*?)</DNP_.*?>\", xml_string)\n",
    "org=list(set(org))\n",
    "\n",
    "if org:\n",
    "    for match in org :\n",
    "        pattern =  r'<[^<>]+?>'\n",
    "        clean_text = re.sub(pattern, '', match).replace('<>', '')\n",
    "        print(clean_text)\n",
    "else:\n",
    "    print(\"No matches found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05e2e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_using_prep=re.findall(r'<prep_in_work(s|ed|ing) />(.*?)</prep_in_work(s|ed|ing) />', xml_string)\n",
    "if matches_using_prep:\n",
    "    for match in matches_using_prep :\n",
    "        pattern =  r'<[^<>]+?>'\n",
    "        clean_text = re.sub(pattern, '', match[1]).replace('<>', '')[2:]\n",
    "        print(clean_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
